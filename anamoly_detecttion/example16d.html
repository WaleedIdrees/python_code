<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <title>mymarkdownfile</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="https://unpkg.com/reveal.js@^4//dist/reset.css">
  <link rel="stylesheet" href="https://unpkg.com/reveal.js@^4//dist/reveal.css">
  <style>
    .reveal .sourceCode {  /* see #7635 */
      overflow: visible;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="https://unpkg.com/reveal.js@^4//dist/theme/black.css" id="theme">
</head>
<body>
  <div class="reveal">
    <div class="slides">


<section class="slide level1">

<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.express <span class="im">as</span> px</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>pd.options.plotting.backend<span class="op">=</span> <span class="st">&quot;plotly&quot;</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">&#39;display.max_columns&#39;</span>, <span class="dv">150</span>, <span class="st">&#39;display.max_rows&#39;</span>, <span class="dv">100</span>, <span class="st">&#39;display.max_colwidth&#39;</span>, <span class="dv">15</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline </span></code></pre></div>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">#!jupyter nbconvert --to markdown --output mymarkdownfile.md Anamoly_detection_credit_card.ipynb</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co">#!pandoc mymarkdownfile.md -s --mathml  -o mathMathML.html</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co">#!pandoc  mymarkdownfile.md  -t revealjs -V theme=white -V slideNumber=true -o index.html</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co">#!pandoc  Anamoly_detection_credit_card.ipynb  -t revealjs -V theme=white -V slideNumber=true -o index1.html</span></span></code></pre></div>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> subprocess</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Replace &quot;my_presentation.md&quot; with the name of your Markdown file</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>md_file <span class="op">=</span> <span class="st">&quot;mymarkdownfile.md&quot;</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert Markdown to HTML</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>html_file <span class="op">=</span> md_file.replace(<span class="st">&quot;.md&quot;</span>, <span class="st">&quot;.html&quot;</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>subprocess.run([<span class="st">&quot;pandoc&quot;</span>, <span class="st">&quot;-f&quot;</span>, <span class="st">&quot;markdown&quot;</span>, <span class="st">&quot;-t&quot;</span>, <span class="st">&quot;html&quot;</span>, <span class="st">&quot;-s&quot;</span>, <span class="st">&quot;-o&quot;</span>, html_file, md_file])</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert HTML to slides</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>slides_file <span class="op">=</span> md_file.replace(<span class="st">&quot;.md&quot;</span>, <span class="st">&quot;.slides.html&quot;</span>)</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>subprocess.run([<span class="st">&quot;pandoc&quot;</span>, <span class="st">&quot;-t&quot;</span>, <span class="st">&quot;revealjs&quot;</span>, <span class="st">&quot;-s&quot;</span>, <span class="st">&quot;-o&quot;</span>, slides_file, html_file])</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co">#Note that you still need to have Pandoc and Python installed on your system and replace &quot;my_presentation.md&quot; with the name of your actual Markdown file.</span></span></code></pre></div>
<pre><code>CompletedProcess(args=[&#39;pandoc&#39;, &#39;-t&#39;, &#39;revealjs&#39;, &#39;-s&#39;, &#39;-o&#39;, &#39;mymarkdownfile.slides.html&#39;, &#39;mymarkdownfile.html&#39;], returncode=0)</code></pre>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="co">#!pandoc -t dzslides mymarkdown.md -o pandoc/dzslides-pandoc.html --embed-resources --standalone</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co">#!pandoc -t slidy habits.md -o pandoc/slidy-pandoc.html --self-contained</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co">#!pandoc -t revealjs habits.md -o pandoc/revealjs-pandoc.html -sV revealjs-url=https://revealjs.com</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co">#!jupyter nbconvert --to slides --output mymarkdownfile.html Anamoly_detection_credit_card.ipynb</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co">#!jupyter nbconvert --to slides --post serve Anamoly_detection_credit_card.ipynb</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co">#!jupyter nbconvert --to slides --execute Anamoly_detection_credit_card.ipynb</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co">#!pip install autoviz</span></span></code></pre></div>
<ul>
<li class="fragment"><p><a href="#/1">Introduction</a></p></li>
<li class="fragment"><p><a href="#/2">Methodology</a></p></li>
<li class="fragment"><p><a href="#/5">Conclusion</a></p></li>
</ul>
<p><a id='1'></a> # Introduction</p>
<ul>
<li class="fragment"><p>In the real world, fraud often goes
undiscovered, and only the fraud that is caught provides any labels for
the datasets.</p></li>
<li class="fragment"><p>Moreover, fraud patterns change over time, so
supervised systems that are built using fraud labels become stale,
capturing historical patterns of fraud but failing to adapt to newly
emerging patterns.</p></li>
<li class="fragment"><p>For these reasons (the lack of sufficient labels
and the need to adapt to newly emerging patterns of fraud as quickly as
possible), unsupervised learning fraud detection systems are in
vogue.</p></li>
<li class="fragment"><p>In this notebook, we will build such a solution
using PCA</p></li>
</ul>
<h2 id="what-is-pca">What is PCA</h2>
<p>PCA (Principal Component Analysis) is a technique to find a
low-dimensional representation of a dataset that captures as much
variation as possible. It seeks a small number of dimensions that are
interesting and informative, where each dimension is a linear
combination of the original features. The first principal component is a
normalized linear combination of the features that has the largest
variance. It can be found through an optimization problem, and the
resulting loadings and scores make up the principal component loading
vector. PCA is useful when the original dataset has a large number of
features, making it difficult to visualize and analyze.</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load dataset</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">&#39;/Users/waleedidrees/Dropbox/Python_Projects/books/handson-unsupervised-learning-master/datasets/credit_card_data/credit_card.csv&#39;</span>).rename(columns<span class="op">=</span> {<span class="st">&quot;Class&quot;</span>:<span class="st">&quot;target&quot;</span>})</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>df.head()</span></code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Time
</th>
<th>
V1
</th>
<th>
V2
</th>
<th>
V3
</th>
<th>
V4
</th>
<th>
V5
</th>
<th>
V6
</th>
<th>
V7
</th>
<th>
V8
</th>
<th>
V9
</th>
<th>
V10
</th>
<th>
V11
</th>
<th>
V12
</th>
<th>
V13
</th>
<th>
V14
</th>
<th>
V15
</th>
<th>
V16
</th>
<th>
V17
</th>
<th>
V18
</th>
<th>
V19
</th>
<th>
V20
</th>
<th>
V21
</th>
<th>
V22
</th>
<th>
V23
</th>
<th>
V24
</th>
<th>
V25
</th>
<th>
V26
</th>
<th>
V27
</th>
<th>
V28
</th>
<th>
Amount
</th>
<th>
target
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
0.0
</td>
<td>
-1.359807
</td>
<td>
-0.072781
</td>
<td>
2.536347
</td>
<td>
1.378155
</td>
<td>
-0.338321
</td>
<td>
0.462388
</td>
<td>
0.239599
</td>
<td>
0.098698
</td>
<td>
0.363787
</td>
<td>
0.090794
</td>
<td>
-0.551600
</td>
<td>
-0.617801
</td>
<td>
-0.991390
</td>
<td>
-0.311169
</td>
<td>
1.468177
</td>
<td>
-0.470401
</td>
<td>
0.207971
</td>
<td>
0.025791
</td>
<td>
0.403993
</td>
<td>
0.251412
</td>
<td>
-0.018307
</td>
<td>
0.277838
</td>
<td>
-0.110474
</td>
<td>
0.066928
</td>
<td>
0.128539
</td>
<td>
-0.189115
</td>
<td>
0.133558
</td>
<td>
-0.021053
</td>
<td>
149.62
</td>
<td>
0
</td>
</tr>
<tr>
<th>
1
</th>
<td>
0.0
</td>
<td>
1.191857
</td>
<td>
0.266151
</td>
<td>
0.166480
</td>
<td>
0.448154
</td>
<td>
0.060018
</td>
<td>
-0.082361
</td>
<td>
-0.078803
</td>
<td>
0.085102
</td>
<td>
-0.255425
</td>
<td>
-0.166974
</td>
<td>
1.612727
</td>
<td>
1.065235
</td>
<td>
0.489095
</td>
<td>
-0.143772
</td>
<td>
0.635558
</td>
<td>
0.463917
</td>
<td>
-0.114805
</td>
<td>
-0.183361
</td>
<td>
-0.145783
</td>
<td>
-0.069083
</td>
<td>
-0.225775
</td>
<td>
-0.638672
</td>
<td>
0.101288
</td>
<td>
-0.339846
</td>
<td>
0.167170
</td>
<td>
0.125895
</td>
<td>
-0.008983
</td>
<td>
0.014724
</td>
<td>
2.69
</td>
<td>
0
</td>
</tr>
<tr>
<th>
2
</th>
<td>
1.0
</td>
<td>
-1.358354
</td>
<td>
-1.340163
</td>
<td>
1.773209
</td>
<td>
0.379780
</td>
<td>
-0.503198
</td>
<td>
1.800499
</td>
<td>
0.791461
</td>
<td>
0.247676
</td>
<td>
-1.514654
</td>
<td>
0.207643
</td>
<td>
0.624501
</td>
<td>
0.066084
</td>
<td>
0.717293
</td>
<td>
-0.165946
</td>
<td>
2.345865
</td>
<td>
-2.890083
</td>
<td>
1.109969
</td>
<td>
-0.121359
</td>
<td>
-2.261857
</td>
<td>
0.524980
</td>
<td>
0.247998
</td>
<td>
0.771679
</td>
<td>
0.909412
</td>
<td>
-0.689281
</td>
<td>
-0.327642
</td>
<td>
-0.139097
</td>
<td>
-0.055353
</td>
<td>
-0.059752
</td>
<td>
378.66
</td>
<td>
0
</td>
</tr>
<tr>
<th>
3
</th>
<td>
1.0
</td>
<td>
-0.966272
</td>
<td>
-0.185226
</td>
<td>
1.792993
</td>
<td>
-0.863291
</td>
<td>
-0.010309
</td>
<td>
1.247203
</td>
<td>
0.237609
</td>
<td>
0.377436
</td>
<td>
-1.387024
</td>
<td>
-0.054952
</td>
<td>
-0.226487
</td>
<td>
0.178228
</td>
<td>
0.507757
</td>
<td>
-0.287924
</td>
<td>
-0.631418
</td>
<td>
-1.059647
</td>
<td>
-0.684093
</td>
<td>
1.965775
</td>
<td>
-1.232622
</td>
<td>
-0.208038
</td>
<td>
-0.108300
</td>
<td>
0.005274
</td>
<td>
-0.190321
</td>
<td>
-1.175575
</td>
<td>
0.647376
</td>
<td>
-0.221929
</td>
<td>
0.062723
</td>
<td>
0.061458
</td>
<td>
123.50
</td>
<td>
0
</td>
</tr>
<tr>
<th>
4
</th>
<td>
2.0
</td>
<td>
-1.158233
</td>
<td>
0.877737
</td>
<td>
1.548718
</td>
<td>
0.403034
</td>
<td>
-0.407193
</td>
<td>
0.095921
</td>
<td>
0.592941
</td>
<td>
-0.270533
</td>
<td>
0.817739
</td>
<td>
0.753074
</td>
<td>
-0.822843
</td>
<td>
0.538196
</td>
<td>
1.345852
</td>
<td>
-1.119670
</td>
<td>
0.175121
</td>
<td>
-0.451449
</td>
<td>
-0.237033
</td>
<td>
-0.038195
</td>
<td>
0.803487
</td>
<td>
0.408542
</td>
<td>
-0.009431
</td>
<td>
0.798278
</td>
<td>
-0.137458
</td>
<td>
0.141267
</td>
<td>
-0.206010
</td>
<td>
0.502292
</td>
<td>
0.219422
</td>
<td>
0.215153
</td>
<td>
69.99
</td>
<td>
0
</td>
</tr>
</tbody>
</table>
</div>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>df.columns<span class="op">=</span> df.columns.<span class="bu">str</span>.lower()</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>df.head()</span></code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
time
</th>
<th>
v1
</th>
<th>
v2
</th>
<th>
v3
</th>
<th>
v4
</th>
<th>
v5
</th>
<th>
v6
</th>
<th>
v7
</th>
<th>
v8
</th>
<th>
v9
</th>
<th>
v10
</th>
<th>
v11
</th>
<th>
v12
</th>
<th>
v13
</th>
<th>
v14
</th>
<th>
v15
</th>
<th>
v16
</th>
<th>
v17
</th>
<th>
v18
</th>
<th>
v19
</th>
<th>
v20
</th>
<th>
v21
</th>
<th>
v22
</th>
<th>
v23
</th>
<th>
v24
</th>
<th>
v25
</th>
<th>
v26
</th>
<th>
v27
</th>
<th>
v28
</th>
<th>
amount
</th>
<th>
target
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
0.0
</td>
<td>
-1.359807
</td>
<td>
-0.072781
</td>
<td>
2.536347
</td>
<td>
1.378155
</td>
<td>
-0.338321
</td>
<td>
0.462388
</td>
<td>
0.239599
</td>
<td>
0.098698
</td>
<td>
0.363787
</td>
<td>
0.090794
</td>
<td>
-0.551600
</td>
<td>
-0.617801
</td>
<td>
-0.991390
</td>
<td>
-0.311169
</td>
<td>
1.468177
</td>
<td>
-0.470401
</td>
<td>
0.207971
</td>
<td>
0.025791
</td>
<td>
0.403993
</td>
<td>
0.251412
</td>
<td>
-0.018307
</td>
<td>
0.277838
</td>
<td>
-0.110474
</td>
<td>
0.066928
</td>
<td>
0.128539
</td>
<td>
-0.189115
</td>
<td>
0.133558
</td>
<td>
-0.021053
</td>
<td>
149.62
</td>
<td>
0
</td>
</tr>
<tr>
<th>
1
</th>
<td>
0.0
</td>
<td>
1.191857
</td>
<td>
0.266151
</td>
<td>
0.166480
</td>
<td>
0.448154
</td>
<td>
0.060018
</td>
<td>
-0.082361
</td>
<td>
-0.078803
</td>
<td>
0.085102
</td>
<td>
-0.255425
</td>
<td>
-0.166974
</td>
<td>
1.612727
</td>
<td>
1.065235
</td>
<td>
0.489095
</td>
<td>
-0.143772
</td>
<td>
0.635558
</td>
<td>
0.463917
</td>
<td>
-0.114805
</td>
<td>
-0.183361
</td>
<td>
-0.145783
</td>
<td>
-0.069083
</td>
<td>
-0.225775
</td>
<td>
-0.638672
</td>
<td>
0.101288
</td>
<td>
-0.339846
</td>
<td>
0.167170
</td>
<td>
0.125895
</td>
<td>
-0.008983
</td>
<td>
0.014724
</td>
<td>
2.69
</td>
<td>
0
</td>
</tr>
<tr>
<th>
2
</th>
<td>
1.0
</td>
<td>
-1.358354
</td>
<td>
-1.340163
</td>
<td>
1.773209
</td>
<td>
0.379780
</td>
<td>
-0.503198
</td>
<td>
1.800499
</td>
<td>
0.791461
</td>
<td>
0.247676
</td>
<td>
-1.514654
</td>
<td>
0.207643
</td>
<td>
0.624501
</td>
<td>
0.066084
</td>
<td>
0.717293
</td>
<td>
-0.165946
</td>
<td>
2.345865
</td>
<td>
-2.890083
</td>
<td>
1.109969
</td>
<td>
-0.121359
</td>
<td>
-2.261857
</td>
<td>
0.524980
</td>
<td>
0.247998
</td>
<td>
0.771679
</td>
<td>
0.909412
</td>
<td>
-0.689281
</td>
<td>
-0.327642
</td>
<td>
-0.139097
</td>
<td>
-0.055353
</td>
<td>
-0.059752
</td>
<td>
378.66
</td>
<td>
0
</td>
</tr>
<tr>
<th>
3
</th>
<td>
1.0
</td>
<td>
-0.966272
</td>
<td>
-0.185226
</td>
<td>
1.792993
</td>
<td>
-0.863291
</td>
<td>
-0.010309
</td>
<td>
1.247203
</td>
<td>
0.237609
</td>
<td>
0.377436
</td>
<td>
-1.387024
</td>
<td>
-0.054952
</td>
<td>
-0.226487
</td>
<td>
0.178228
</td>
<td>
0.507757
</td>
<td>
-0.287924
</td>
<td>
-0.631418
</td>
<td>
-1.059647
</td>
<td>
-0.684093
</td>
<td>
1.965775
</td>
<td>
-1.232622
</td>
<td>
-0.208038
</td>
<td>
-0.108300
</td>
<td>
0.005274
</td>
<td>
-0.190321
</td>
<td>
-1.175575
</td>
<td>
0.647376
</td>
<td>
-0.221929
</td>
<td>
0.062723
</td>
<td>
0.061458
</td>
<td>
123.50
</td>
<td>
0
</td>
</tr>
<tr>
<th>
4
</th>
<td>
2.0
</td>
<td>
-1.158233
</td>
<td>
0.877737
</td>
<td>
1.548718
</td>
<td>
0.403034
</td>
<td>
-0.407193
</td>
<td>
0.095921
</td>
<td>
0.592941
</td>
<td>
-0.270533
</td>
<td>
0.817739
</td>
<td>
0.753074
</td>
<td>
-0.822843
</td>
<td>
0.538196
</td>
<td>
1.345852
</td>
<td>
-1.119670
</td>
<td>
0.175121
</td>
<td>
-0.451449
</td>
<td>
-0.237033
</td>
<td>
-0.038195
</td>
<td>
0.803487
</td>
<td>
0.408542
</td>
<td>
-0.009431
</td>
<td>
0.798278
</td>
<td>
-0.137458
</td>
<td>
0.141267
</td>
<td>
-0.206010
</td>
<td>
0.502292
</td>
<td>
0.219422
</td>
<td>
0.215153
</td>
<td>
69.99
</td>
<td>
0
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="disable-the-warnings" class="slide level1">
<h1>Disable the warnings</h1>
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">&#39;ignore&#39;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>df.describe().T</span></code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
count
</th>
<th>
mean
</th>
<th>
std
</th>
<th>
min
</th>
<th>
25%
</th>
<th>
50%
</th>
<th>
75%
</th>
<th>
max
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
time
</th>
<td>
284807.0
</td>
<td>
9.481386e+04
</td>
<td>
47488.145955
</td>
<td>
0.000000
</td>
<td>
54201.500000
</td>
<td>
84692.000000
</td>
<td>
139320.500000
</td>
<td>
172792.000000
</td>
</tr>
<tr>
<th>
v1
</th>
<td>
284807.0
</td>
<td>
1.168375e-15
</td>
<td>
1.958696
</td>
<td>
-56.407510
</td>
<td>
-0.920373
</td>
<td>
0.018109
</td>
<td>
1.315642
</td>
<td>
2.454930
</td>
</tr>
<tr>
<th>
v2
</th>
<td>
284807.0
</td>
<td>
3.416908e-16
</td>
<td>
1.651309
</td>
<td>
-72.715728
</td>
<td>
-0.598550
</td>
<td>
0.065486
</td>
<td>
0.803724
</td>
<td>
22.057729
</td>
</tr>
<tr>
<th>
v3
</th>
<td>
284807.0
</td>
<td>
-1.379537e-15
</td>
<td>
1.516255
</td>
<td>
-48.325589
</td>
<td>
-0.890365
</td>
<td>
0.179846
</td>
<td>
1.027196
</td>
<td>
9.382558
</td>
</tr>
<tr>
<th>
v4
</th>
<td>
284807.0
</td>
<td>
2.074095e-15
</td>
<td>
1.415869
</td>
<td>
-5.683171
</td>
<td>
-0.848640
</td>
<td>
-0.019847
</td>
<td>
0.743341
</td>
<td>
16.875344
</td>
</tr>
<tr>
<th>
v5
</th>
<td>
284807.0
</td>
<td>
9.604066e-16
</td>
<td>
1.380247
</td>
<td>
-113.743307
</td>
<td>
-0.691597
</td>
<td>
-0.054336
</td>
<td>
0.611926
</td>
<td>
34.801666
</td>
</tr>
<tr>
<th>
v6
</th>
<td>
284807.0
</td>
<td>
1.487313e-15
</td>
<td>
1.332271
</td>
<td>
-26.160506
</td>
<td>
-0.768296
</td>
<td>
-0.274187
</td>
<td>
0.398565
</td>
<td>
73.301626
</td>
</tr>
<tr>
<th>
v7
</th>
<td>
284807.0
</td>
<td>
-5.556467e-16
</td>
<td>
1.237094
</td>
<td>
-43.557242
</td>
<td>
-0.554076
</td>
<td>
0.040103
</td>
<td>
0.570436
</td>
<td>
120.589494
</td>
</tr>
<tr>
<th>
v8
</th>
<td>
284807.0
</td>
<td>
1.213481e-16
</td>
<td>
1.194353
</td>
<td>
-73.216718
</td>
<td>
-0.208630
</td>
<td>
0.022358
</td>
<td>
0.327346
</td>
<td>
20.007208
</td>
</tr>
<tr>
<th>
v9
</th>
<td>
284807.0
</td>
<td>
-2.406331e-15
</td>
<td>
1.098632
</td>
<td>
-13.434066
</td>
<td>
-0.643098
</td>
<td>
-0.051429
</td>
<td>
0.597139
</td>
<td>
15.594995
</td>
</tr>
<tr>
<th>
v10
</th>
<td>
284807.0
</td>
<td>
2.239053e-15
</td>
<td>
1.088850
</td>
<td>
-24.588262
</td>
<td>
-0.535426
</td>
<td>
-0.092917
</td>
<td>
0.453923
</td>
<td>
23.745136
</td>
</tr>
<tr>
<th>
v11
</th>
<td>
284807.0
</td>
<td>
1.673327e-15
</td>
<td>
1.020713
</td>
<td>
-4.797473
</td>
<td>
-0.762494
</td>
<td>
-0.032757
</td>
<td>
0.739593
</td>
<td>
12.018913
</td>
</tr>
<tr>
<th>
v12
</th>
<td>
284807.0
</td>
<td>
-1.247012e-15
</td>
<td>
0.999201
</td>
<td>
-18.683715
</td>
<td>
-0.405571
</td>
<td>
0.140033
</td>
<td>
0.618238
</td>
<td>
7.848392
</td>
</tr>
<tr>
<th>
v13
</th>
<td>
284807.0
</td>
<td>
8.190001e-16
</td>
<td>
0.995274
</td>
<td>
-5.791881
</td>
<td>
-0.648539
</td>
<td>
-0.013568
</td>
<td>
0.662505
</td>
<td>
7.126883
</td>
</tr>
<tr>
<th>
v14
</th>
<td>
284807.0
</td>
<td>
1.207294e-15
</td>
<td>
0.958596
</td>
<td>
-19.214325
</td>
<td>
-0.425574
</td>
<td>
0.050601
</td>
<td>
0.493150
</td>
<td>
10.526766
</td>
</tr>
<tr>
<th>
v15
</th>
<td>
284807.0
</td>
<td>
4.887456e-15
</td>
<td>
0.915316
</td>
<td>
-4.498945
</td>
<td>
-0.582884
</td>
<td>
0.048072
</td>
<td>
0.648821
</td>
<td>
8.877742
</td>
</tr>
<tr>
<th>
v16
</th>
<td>
284807.0
</td>
<td>
1.437716e-15
</td>
<td>
0.876253
</td>
<td>
-14.129855
</td>
<td>
-0.468037
</td>
<td>
0.066413
</td>
<td>
0.523296
</td>
<td>
17.315112
</td>
</tr>
<tr>
<th>
v17
</th>
<td>
284807.0
</td>
<td>
-3.772171e-16
</td>
<td>
0.849337
</td>
<td>
-25.162799
</td>
<td>
-0.483748
</td>
<td>
-0.065676
</td>
<td>
0.399675
</td>
<td>
9.253526
</td>
</tr>
<tr>
<th>
v18
</th>
<td>
284807.0
</td>
<td>
9.564149e-16
</td>
<td>
0.838176
</td>
<td>
-9.498746
</td>
<td>
-0.498850
</td>
<td>
-0.003636
</td>
<td>
0.500807
</td>
<td>
5.041069
</td>
</tr>
<tr>
<th>
v19
</th>
<td>
284807.0
</td>
<td>
1.039917e-15
</td>
<td>
0.814041
</td>
<td>
-7.213527
</td>
<td>
-0.456299
</td>
<td>
0.003735
</td>
<td>
0.458949
</td>
<td>
5.591971
</td>
</tr>
<tr>
<th>
v20
</th>
<td>
284807.0
</td>
<td>
6.406204e-16
</td>
<td>
0.770925
</td>
<td>
-54.497720
</td>
<td>
-0.211721
</td>
<td>
-0.062481
</td>
<td>
0.133041
</td>
<td>
39.420904
</td>
</tr>
<tr>
<th>
v21
</th>
<td>
284807.0
</td>
<td>
1.654067e-16
</td>
<td>
0.734524
</td>
<td>
-34.830382
</td>
<td>
-0.228395
</td>
<td>
-0.029450
</td>
<td>
0.186377
</td>
<td>
27.202839
</td>
</tr>
<tr>
<th>
v22
</th>
<td>
284807.0
</td>
<td>
-3.568593e-16
</td>
<td>
0.725702
</td>
<td>
-10.933144
</td>
<td>
-0.542350
</td>
<td>
0.006782
</td>
<td>
0.528554
</td>
<td>
10.503090
</td>
</tr>
<tr>
<th>
v23
</th>
<td>
284807.0
</td>
<td>
2.578648e-16
</td>
<td>
0.624460
</td>
<td>
-44.807735
</td>
<td>
-0.161846
</td>
<td>
-0.011193
</td>
<td>
0.147642
</td>
<td>
22.528412
</td>
</tr>
<tr>
<th>
v24
</th>
<td>
284807.0
</td>
<td>
4.473266e-15
</td>
<td>
0.605647
</td>
<td>
-2.836627
</td>
<td>
-0.354586
</td>
<td>
0.040976
</td>
<td>
0.439527
</td>
<td>
4.584549
</td>
</tr>
<tr>
<th>
v25
</th>
<td>
284807.0
</td>
<td>
5.340915e-16
</td>
<td>
0.521278
</td>
<td>
-10.295397
</td>
<td>
-0.317145
</td>
<td>
0.016594
</td>
<td>
0.350716
</td>
<td>
7.519589
</td>
</tr>
<tr>
<th>
v26
</th>
<td>
284807.0
</td>
<td>
1.683437e-15
</td>
<td>
0.482227
</td>
<td>
-2.604551
</td>
<td>
-0.326984
</td>
<td>
-0.052139
</td>
<td>
0.240952
</td>
<td>
3.517346
</td>
</tr>
<tr>
<th>
v27
</th>
<td>
284807.0
</td>
<td>
-3.660091e-16
</td>
<td>
0.403632
</td>
<td>
-22.565679
</td>
<td>
-0.070840
</td>
<td>
0.001342
</td>
<td>
0.091045
</td>
<td>
31.612198
</td>
</tr>
<tr>
<th>
v28
</th>
<td>
284807.0
</td>
<td>
-1.227390e-16
</td>
<td>
0.330083
</td>
<td>
-15.430084
</td>
<td>
-0.052960
</td>
<td>
0.011244
</td>
<td>
0.078280
</td>
<td>
33.847808
</td>
</tr>
<tr>
<th>
amount
</th>
<td>
284807.0
</td>
<td>
8.834962e+01
</td>
<td>
250.120109
</td>
<td>
0.000000
</td>
<td>
5.600000
</td>
<td>
22.000000
</td>
<td>
77.165000
</td>
<td>
25691.160000
</td>
</tr>
<tr>
<th>
target
</th>
<td>
284807.0
</td>
<td>
1.727486e-03
</td>
<td>
0.041527
</td>
<td>
0.000000
</td>
<td>
0.000000
</td>
<td>
0.000000
</td>
<td>
0.000000
</td>
<td>
1.000000
</td>
</tr>
</tbody>
</table>
</div>
<h2
id="we-see-that-fraudulent-transactions-are-very-rare-and-this-makes-the-data-very-imbalanced">we
see that fraudulent transactions are very rare and this makes the data
very imbalanced</h2>
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&quot;target&quot;</span>].value_counts().reset_index()</span></code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
index
</th>
<th>
target
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
0
</td>
<td>
284315
</td>
</tr>
<tr>
<th>
1
</th>
<td>
1
</td>
<td>
492
</td>
</tr>
</tbody>
</table>
</div>
<p>we have 284,807 credit card transactions in total, of which 492 are
fraudulent, with a positive (fraud) label of one. The rest are normal
transactions, with a negative (not fraud) label of zero. We have 30
features to use for anomaly detectionâ€”time, amount, and 28 principal
components. And, we will split the dataset into a training set (with
190,820 transactions and 330 cases of fraud) and a test set (with the
remaining 93,987 transactions and 162 cases of fraud)</p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&quot;target&quot;</span>]</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>.value_counts()</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>.reset_index()</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>.plot.bar(x<span class="op">=</span><span class="st">&quot;index&quot;</span>, y<span class="op">=</span> <span class="st">&quot;target&quot;</span>, color<span class="op">=</span><span class="st">&quot;index&quot;</span>, height<span class="op">=</span> <span class="dv">800</span>, width<span class="op">=</span> <span class="dv">800</span>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a> )</span></code></pre></div>
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>pd.options.plotting.backend <span class="op">=</span> <span class="st">&quot;matplotlib&quot;</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>df.hist(figsize<span class="op">=</span> (<span class="dv">22</span>,<span class="dv">16</span>), bins<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>pd.options.plotting.backend <span class="op">=</span> <span class="st">&quot;plotly&quot;</span></span></code></pre></div>
<figure>
<img data-src="mymarkdownfile_files/mymarkdownfile_15_0.png"
alt="png" />
<figcaption aria-hidden="true">png</figcaption>
</figure>
<p><a id='2'></a></p>
<h2 id="methodology">Methodology</h2>
<p>Since this an unsupervised learning problem and we will not be using
the labels so we need find a way to measure the performance of the
anamoly model. Dimensionality reduction algorithms reduce the
dimensionality of data while attempting to minimize the reconstruction
error. However, these dimensionality reduction algorithms cannot capture
all the information of the original features as they move to a lower
dimensional space; therefore, there will be some error as these
algorithms reconstruct the reduced feature set back to the original
number of dimensions. we will use these errors and make a function to
compare them to the original dataframe and measure the score. we make
our performance measure as follows:</p>
<ul>
<li class="fragment">We take the difference between the original vs the
pca dataframe which we created from pcs components using inverse
transformation</li>
<li class="fragment">then we transform the difference using min max
scaller from 0 to 1 scale</li>
<li class="fragment">we can consider this score as probability score and
use this against the labels to calculate, precision, recall and
threshhold using sklearn precision recall curve metric.</li>
<li class="fragment">We will take x number of highest scores as our
anomolies</li>
<li class="fragment">we can all also calculate average precision score
using the average precision score metric.</li>
</ul>
</section>
<section id="define-evaluation-functions" class="slide level1">
<h1>Define evaluation functions</h1>
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate reconstruction error</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> anomalyScores(originalDF, pca_df):</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> ((originalDF.values<span class="op">-</span> pca_df.values)<span class="op">**</span><span class="dv">2</span>).<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)    </span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> pd.Series(data<span class="op">=</span>loss,index<span class="op">=</span>originalDF.index)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> (loss<span class="op">-</span>np.<span class="bu">min</span>(loss))<span class="op">/</span>(np.<span class="bu">max</span>(loss)<span class="op">-</span>np.<span class="bu">min</span>(loss))</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> loss</span></code></pre></div>
</section>
<section id="train-test-splits" class="slide level1">
<h1>Train-test splits</h1>
<p>We will remove the target variable and we will not be using it for
training but we will use it to evaluate the anamolies by attaching it to
anamoly scores</p>
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span>  train_test_split(df.drop(columns<span class="op">=</span>[<span class="st">&quot;target&quot;</span>,<span class="st">&quot;time&quot;</span>]).copy(), df[<span class="st">&quot;target&quot;</span>], test_size <span class="op">=</span> <span class="fl">0.33</span>,stratify<span class="op">=</span>df[<span class="st">&quot;target&quot;</span>],  random_state <span class="op">=</span> <span class="dv">2018</span> )</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>X_train.shape, y_train.shape, X_test.shape, y_test.shape</span></code></pre></div>
<pre><code>((190820, 29), (190820,), (93987, 29), (93987,))</code></pre>
<p>The train data has 330 Fraudulent transaction and 190490 normal
transactions</p>
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>y_train.value_counts()</span></code></pre></div>
<pre><code>0    190490
1       330
Name: target, dtype: int64</code></pre>
</section>
<section id="lets-create-preprocessing-pipiline" class="slide level1">
<h1>Lets create Preprocessing Pipiline</h1>
<ul>
<li class="fragment">all our variables are numeric we will standardise
data and then as for PCA we must standardise observations.</li>
</ul>
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.compose <span class="im">import</span> ColumnTransformer</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.impute <span class="im">import</span> KNNImputer</span></code></pre></div>
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>num_pipe<span class="op">=</span> Pipeline ( steps<span class="op">=</span>[</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    (<span class="st">&quot;std&quot;</span>, StandardScaler()),</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    (<span class="st">&quot;impute&quot;</span>, KNNImputer()), </span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    ])</span></code></pre></div>
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>all_cols<span class="op">=</span> X_train.columns</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>prep<span class="op">=</span> ColumnTransformer([</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>    (<span class="st">&quot;n&quot;</span>, num_pipe, all_cols)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    ]).set_output(transform<span class="op">=</span> <span class="st">&quot;pandas&quot;</span>)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>prep.fit_transform(X_train).head()</span></code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
n__v1
</th>
<th>
n__v2
</th>
<th>
n__v3
</th>
<th>
n__v4
</th>
<th>
n__v5
</th>
<th>
n__v6
</th>
<th>
n__v7
</th>
<th>
n__v8
</th>
<th>
n__v9
</th>
<th>
n__v10
</th>
<th>
n__v11
</th>
<th>
n__v12
</th>
<th>
n__v13
</th>
<th>
n__v14
</th>
<th>
n__v15
</th>
<th>
n__v16
</th>
<th>
n__v17
</th>
<th>
n__v18
</th>
<th>
n__v19
</th>
<th>
n__v20
</th>
<th>
n__v21
</th>
<th>
n__v22
</th>
<th>
n__v23
</th>
<th>
n__v24
</th>
<th>
n__v25
</th>
<th>
n__v26
</th>
<th>
n__v27
</th>
<th>
n__v28
</th>
<th>
n__amount
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
142087
</th>
<td>
-1.008613
</td>
<td>
1.168013
</td>
<td>
0.203077
</td>
<td>
-0.252933
</td>
<td>
-0.387030
</td>
<td>
-0.051340
</td>
<td>
-0.191393
</td>
<td>
0.917626
</td>
<td>
-0.220348
</td>
<td>
0.379391
</td>
<td>
0.891953
</td>
<td>
0.652099
</td>
<td>
-0.481673
</td>
<td>
0.888920
</td>
<td>
0.511094
</td>
<td>
0.459652
</td>
<td>
-0.178769
</td>
<td>
-0.131099
</td>
<td>
-0.030699
</td>
<td>
0.240351
</td>
<td>
-0.230649
</td>
<td>
-0.781406
</td>
<td>
0.154163
</td>
<td>
-0.584578
</td>
<td>
-0.161870
</td>
<td>
0.232116
</td>
<td>
0.525621
</td>
<td>
0.459397
</td>
<td>
-0.301324
</td>
</tr>
<tr>
<th>
165168
</th>
<td>
0.071848
</td>
<td>
0.664025
</td>
<td>
-0.240845
</td>
<td>
-0.381091
</td>
<td>
0.694608
</td>
<td>
-0.633906
</td>
<td>
0.833474
</td>
<td>
-0.132701
</td>
<td>
-0.166967
</td>
<td>
-0.793682
</td>
<td>
-0.490992
</td>
<td>
0.366808
</td>
<td>
0.879055
</td>
<td>
-1.245368
</td>
<td>
-0.369767
</td>
<td>
0.316392
</td>
<td>
0.393419
</td>
<td>
-0.407275
</td>
<td>
-0.310150
</td>
<td>
0.099453
</td>
<td>
-0.438520
</td>
<td>
-1.037593
</td>
<td>
0.145573
</td>
<td>
1.078771
</td>
<td>
-0.761303
</td>
<td>
0.221753
</td>
<td>
0.564899
</td>
<td>
0.254973
</td>
<td>
-0.342346
</td>
</tr>
<tr>
<th>
235908
</th>
<td>
0.099163
</td>
<td>
-0.387383
</td>
<td>
-0.945009
</td>
<td>
-1.493663
</td>
<td>
-0.092322
</td>
<td>
-0.878326
</td>
<td>
1.252531
</td>
<td>
-0.564372
</td>
<td>
-2.760963
</td>
<td>
0.979945
</td>
<td>
-0.734286
</td>
<td>
-0.940293
</td>
<td>
0.749094
</td>
<td>
0.176712
</td>
<td>
-1.084605
</td>
<td>
-2.049873
</td>
<td>
1.119388
</td>
<td>
-0.424709
</td>
<td>
0.039325
</td>
<td>
0.136822
</td>
<td>
0.597949
</td>
<td>
2.047828
</td>
<td>
0.533608
</td>
<td>
1.885871
</td>
<td>
-0.949325
</td>
<td>
0.195840
</td>
<td>
0.394576
</td>
<td>
0.789716
</td>
<td>
0.507010
</td>
</tr>
<tr>
<th>
148255
</th>
<td>
0.015486
</td>
<td>
0.519611
</td>
<td>
0.193472
</td>
<td>
-0.418969
</td>
<td>
0.316777
</td>
<td>
-0.774851
</td>
<td>
0.816615
</td>
<td>
-0.154107
</td>
<td>
-0.060485
</td>
<td>
-0.393037
</td>
<td>
-0.838072
</td>
<td>
0.229399
</td>
<td>
0.138905
</td>
<td>
0.095691
</td>
<td>
-0.404080
</td>
<td>
-0.180757
</td>
<td>
-0.428453
</td>
<td>
-1.022053
</td>
<td>
-0.193808
</td>
<td>
-0.038190
</td>
<td>
-0.336778
</td>
<td>
-0.738483
</td>
<td>
0.127711
</td>
<td>
-0.026519
</td>
<td>
-0.955999
</td>
<td>
0.297594
</td>
<td>
0.620507
</td>
<td>
0.285961
</td>
<td>
-0.333753
</td>
</tr>
<tr>
<th>
145672
</th>
<td>
0.009053
</td>
<td>
0.524138
</td>
<td>
0.175338
</td>
<td>
-0.335413
</td>
<td>
0.761346
</td>
<td>
0.501074
</td>
<td>
0.266188
</td>
<td>
0.187765
</td>
<td>
-0.186259
</td>
<td>
-0.837330
</td>
<td>
0.231244
</td>
<td>
0.693028
</td>
<td>
1.261985
</td>
<td>
-1.542311
</td>
<td>
-0.324732
</td>
<td>
1.234117
</td>
<td>
-0.316896
</td>
<td>
1.377317
</td>
<td>
0.854111
</td>
<td>
0.109213
</td>
<td>
-0.199423
</td>
<td>
-0.454902
</td>
<td>
0.047231
</td>
<td>
-0.725277
</td>
<td>
-2.181428
</td>
<td>
-0.147735
</td>
<td>
0.586351
</td>
<td>
0.739459
</td>
<td>
-0.337806
</td>
</tr>
</tbody>
</table>
</div>
<h2 id="pca-custom-class">PCA custom class</h2>
<ul>
<li class="fragment">We create a Custom Transformer which will give us
labels on the basis of top 350 highest anomoly score using our
performace score function</li>
<li class="fragment">this will be added in predict method.</li>
</ul>
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.base <span class="im">import</span> MetaEstimatorMixin, clone</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.base <span class="im">import</span> BaseEstimator, TransformerMixin</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> pca_anom(BaseEstimator, TransformerMixin):</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,estimator, top_x):           </span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.estimator <span class="op">=</span> estimator</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.top_x <span class="op">=</span>top_x</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, X,y<span class="op">=</span><span class="va">None</span>):       </span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>       estimator_<span class="op">=</span> clone(<span class="va">self</span>.estimator)</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>       <span class="va">self</span>.model<span class="op">=</span> estimator_.fit(X)</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>       <span class="cf">return</span> <span class="va">self</span>   </span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> transform(<span class="va">self</span>, X, y<span class="op">=</span><span class="va">None</span>):                </span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.columns <span class="op">=</span> <span class="va">self</span>.model.transform(X).shape[<span class="dv">1</span>]        </span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.model.transform(X)</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_feature_names_out(<span class="va">self</span>, names<span class="op">=</span><span class="va">None</span>):        </span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> [<span class="ss">f&#39;pca</span><span class="sc">{</span>x<span class="sc">}</span><span class="ss">&#39;</span><span class="cf">for</span> x <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.columns) ]    </span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, X ):                   </span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>        df_pca_inv<span class="op">=</span> pd.DataFrame(<span class="va">self</span>.model.inverse_transform(<span class="va">self</span>.model.transform(X)))</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>        df_pca_inv.columns<span class="op">=</span> X.columns       </span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>        results<span class="op">=</span> pd.DataFrame()        </span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>        results[<span class="st">&quot;prob&quot;</span>]<span class="op">=</span> anomalyScores(X,df_pca_inv)</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>        anamloies<span class="op">=</span> results.sort_values(<span class="st">&quot;prob&quot;</span> , ascending<span class="op">=</span> <span class="va">False</span>).head(<span class="va">self</span>.top_x)        </span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>        results<span class="op">=</span> results.assign(class_<span class="op">=</span>  np.where(results.index.isin(anamloies.index), <span class="dv">1</span>,<span class="dv">0</span> ))</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> results[[<span class="st">&quot;class_&quot;</span>]]</span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict_proba(<span class="va">self</span>, X ):             </span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>        df_pca_inv<span class="op">=</span> pd.DataFrame(<span class="va">self</span>.model.inverse_transform(<span class="va">self</span>.model.transform(X)))</span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>        df_pca_inv.columns<span class="op">=</span> X.columns       </span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a>        results<span class="op">=</span> pd.DataFrame()        </span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>        results[<span class="st">&quot;prob&quot;</span>]<span class="op">=</span> anomalyScores(X,df_pca_inv)</span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> results</span></code></pre></div>
</section>
<section
id="lets-define-evaluation-function-to-measure-the-recall-precision-and-roc_auc-score"
class="slide level1">
<h1>Lets define Evaluation Function to measure the recall, precision and
roc_auc score</h1>
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluation Functions</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, recall_score ,average_precision_score, precision_recall_curve, precision_score, roc_auc_score,roc_curve, auc </span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> eval_scores(actuals, pred):</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    res<span class="op">=</span> pd.DataFrame({ </span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;accuracy&quot;</span>: [accuracy_score(actuals, pred)], </span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;recall&quot;</span>: [recall_score(actuals, pred)],</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;roc_auc&quot;</span>: [roc_auc_score(actuals, pred)],</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;precision&quot;</span>: [precision_score(actuals, pred)]})    </span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> res</span></code></pre></div>
</section>
<section
id="define-our-pca-model-pipeline-and-see-if-it-works-fine-with-custom-transformer"
class="slide level1">
<h1>Define our PCA model pipeline and see if it works fine with custom
Transformer</h1>
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> FastICA</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>pipe<span class="op">=</span> Pipeline(steps<span class="op">=</span>[</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>    (<span class="st">&quot;preprocess&quot;</span>, prep),    </span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    (<span class="st">&#39;model&#39;</span>, pca_anom(PCA(n_components<span class="op">=</span> <span class="dv">29</span>, random_state<span class="op">=</span><span class="dv">2018</span>), top_x<span class="op">=</span><span class="dv">350</span>))        </span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>    ]).set_output(transform<span class="op">=</span><span class="st">&quot;pandas&quot;</span>)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>pipe.fit(X_train,y_train)</span></code></pre></div>
<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "â–¸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "â–¾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style>
<div id="sk-container-id-1" class="sk-top-container">
<div class="sk-text-repr-fallback">
<pre>Pipeline(steps=[(&#x27;preprocess&#x27;,
                 ColumnTransformer(transformers=[(&#x27;n&#x27;,
                                                  Pipeline(steps=[(&#x27;std&#x27;,
                                                                   StandardScaler()),
                                                                  (&#x27;impute&#x27;,
                                                                   KNNImputer())]),
                                                  Index([&#x27;v1&#x27;, &#x27;v2&#x27;, &#x27;v3&#x27;, &#x27;v4&#x27;, &#x27;v5&#x27;, &#x27;v6&#x27;, &#x27;v7&#x27;, &#x27;v8&#x27;, &#x27;v9&#x27;, &#x27;v10&#x27;, &#x27;v11&#x27;,
       &#x27;v12&#x27;, &#x27;v13&#x27;, &#x27;v14&#x27;, &#x27;v15&#x27;, &#x27;v16&#x27;, &#x27;v17&#x27;, &#x27;v18&#x27;, &#x27;v19&#x27;, &#x27;v20&#x27;, &#x27;v21&#x27;,
       &#x27;v22&#x27;, &#x27;v23&#x27;, &#x27;v24&#x27;, &#x27;v25&#x27;, &#x27;v26&#x27;, &#x27;v27&#x27;, &#x27;v28&#x27;, &#x27;amount&#x27;],
      dtype=&#x27;object&#x27;))])),
                (&#x27;model&#x27;,
                 pca_anom(estimator=PCA(n_components=29, random_state=2018),
                          top_x=350))])</pre>
<b>In a Jupyter environment, please rerun this cell to show the HTML
representation or trust the notebook. <br />On GitHub, the HTML
representation is unable to render, please try loading this page with
nbviewer.org.</b>
</div>
<div class="sk-container" hidden="">
<div class="sk-item sk-dashed-wrapped">
<div class="sk-label-container">
<div class="sk-label sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" ><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">Pipeline</label>
<div class="sk-toggleable__content">
<pre>Pipeline(steps=[(&#x27;preprocess&#x27;,
                 ColumnTransformer(transformers=[(&#x27;n&#x27;,
                                                  Pipeline(steps=[(&#x27;std&#x27;,
                                                                   StandardScaler()),
                                                                  (&#x27;impute&#x27;,
                                                                   KNNImputer())]),
                                                  Index([&#x27;v1&#x27;, &#x27;v2&#x27;, &#x27;v3&#x27;, &#x27;v4&#x27;, &#x27;v5&#x27;, &#x27;v6&#x27;, &#x27;v7&#x27;, &#x27;v8&#x27;, &#x27;v9&#x27;, &#x27;v10&#x27;, &#x27;v11&#x27;,
       &#x27;v12&#x27;, &#x27;v13&#x27;, &#x27;v14&#x27;, &#x27;v15&#x27;, &#x27;v16&#x27;, &#x27;v17&#x27;, &#x27;v18&#x27;, &#x27;v19&#x27;, &#x27;v20&#x27;, &#x27;v21&#x27;,
       &#x27;v22&#x27;, &#x27;v23&#x27;, &#x27;v24&#x27;, &#x27;v25&#x27;, &#x27;v26&#x27;, &#x27;v27&#x27;, &#x27;v28&#x27;, &#x27;amount&#x27;],
      dtype=&#x27;object&#x27;))])),
                (&#x27;model&#x27;,
                 pca_anom(estimator=PCA(n_components=29, random_state=2018),
                          top_x=350))])</pre>
</div>
</div>
</div>
<div class="sk-serial">
<div class="sk-item sk-dashed-wrapped">
<div class="sk-label-container">
<div class="sk-label sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" ><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">preprocess:
ColumnTransformer</label>
<div class="sk-toggleable__content">
<pre>ColumnTransformer(transformers=[(&#x27;n&#x27;,
                                 Pipeline(steps=[(&#x27;std&#x27;, StandardScaler()),
                                                 (&#x27;impute&#x27;, KNNImputer())]),
                                 Index([&#x27;v1&#x27;, &#x27;v2&#x27;, &#x27;v3&#x27;, &#x27;v4&#x27;, &#x27;v5&#x27;, &#x27;v6&#x27;, &#x27;v7&#x27;, &#x27;v8&#x27;, &#x27;v9&#x27;, &#x27;v10&#x27;, &#x27;v11&#x27;,
       &#x27;v12&#x27;, &#x27;v13&#x27;, &#x27;v14&#x27;, &#x27;v15&#x27;, &#x27;v16&#x27;, &#x27;v17&#x27;, &#x27;v18&#x27;, &#x27;v19&#x27;, &#x27;v20&#x27;, &#x27;v21&#x27;,
       &#x27;v22&#x27;, &#x27;v23&#x27;, &#x27;v24&#x27;, &#x27;v25&#x27;, &#x27;v26&#x27;, &#x27;v27&#x27;, &#x27;v28&#x27;, &#x27;amount&#x27;],
      dtype=&#x27;object&#x27;))])</pre>
</div>
</div>
</div>
<div class="sk-parallel">
<div class="sk-parallel-item">
<div class="sk-item">
<div class="sk-label-container">
<div class="sk-label sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" ><label for="sk-estimator-id-3" class="sk-toggleable__label sk-toggleable__label-arrow">n</label>
<div class="sk-toggleable__content">
<pre>Index([&#x27;v1&#x27;, &#x27;v2&#x27;, &#x27;v3&#x27;, &#x27;v4&#x27;, &#x27;v5&#x27;, &#x27;v6&#x27;, &#x27;v7&#x27;, &#x27;v8&#x27;, &#x27;v9&#x27;, &#x27;v10&#x27;, &#x27;v11&#x27;,
       &#x27;v12&#x27;, &#x27;v13&#x27;, &#x27;v14&#x27;, &#x27;v15&#x27;, &#x27;v16&#x27;, &#x27;v17&#x27;, &#x27;v18&#x27;, &#x27;v19&#x27;, &#x27;v20&#x27;, &#x27;v21&#x27;,
       &#x27;v22&#x27;, &#x27;v23&#x27;, &#x27;v24&#x27;, &#x27;v25&#x27;, &#x27;v26&#x27;, &#x27;v27&#x27;, &#x27;v28&#x27;, &#x27;amount&#x27;],
      dtype=&#x27;object&#x27;)</pre>
</div>
</div>
</div>
<div class="sk-serial">
<div class="sk-item">
<div class="sk-serial">
<div class="sk-item">
<div class="sk-estimator sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox" ><label for="sk-estimator-id-4" class="sk-toggleable__label sk-toggleable__label-arrow">StandardScaler</label>
<div class="sk-toggleable__content">
<pre>StandardScaler()</pre>
</div>
</div>
</div>
<div class="sk-item">
<div class="sk-estimator sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-5" type="checkbox" ><label for="sk-estimator-id-5" class="sk-toggleable__label sk-toggleable__label-arrow">KNNImputer</label>
<div class="sk-toggleable__content">
<pre>KNNImputer()</pre>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sk-item sk-dashed-wrapped">
<div class="sk-label-container">
<div class="sk-label sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-6" type="checkbox" ><label for="sk-estimator-id-6" class="sk-toggleable__label sk-toggleable__label-arrow">model:
pca_anom</label>
<div class="sk-toggleable__content">
<pre>pca_anom(estimator=PCA(n_components=29, random_state=2018), top_x=350)</pre>
</div>
</div>
</div>
<div class="sk-parallel">
<div class="sk-parallel-item">
<div class="sk-item">
<div class="sk-label-container">
<div class="sk-label sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-7" type="checkbox" ><label for="sk-estimator-id-7" class="sk-toggleable__label sk-toggleable__label-arrow">estimator:
PCA</label>
<div class="sk-toggleable__content">
<pre>PCA(n_components=29, random_state=2018)</pre>
</div>
</div>
</div>
<div class="sk-serial">
<div class="sk-item">
<div class="sk-estimator sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-8" type="checkbox" ><label for="sk-estimator-id-8" class="sk-toggleable__label sk-toggleable__label-arrow">PCA</label>
<div class="sk-toggleable__content">
<pre>PCA(n_components=29, random_state=2018)</pre>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>pipe.fit_transform(X_train,y_train).head()</span></code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
pca0
</th>
<th>
pca1
</th>
<th>
pca2
</th>
<th>
pca3
</th>
<th>
pca4
</th>
<th>
pca5
</th>
<th>
pca6
</th>
<th>
pca7
</th>
<th>
pca8
</th>
<th>
pca9
</th>
<th>
pca10
</th>
<th>
pca11
</th>
<th>
pca12
</th>
<th>
pca13
</th>
<th>
pca14
</th>
<th>
pca15
</th>
<th>
pca16
</th>
<th>
pca17
</th>
<th>
pca18
</th>
<th>
pca19
</th>
<th>
pca20
</th>
<th>
pca21
</th>
<th>
pca22
</th>
<th>
pca23
</th>
<th>
pca24
</th>
<th>
pca25
</th>
<th>
pca26
</th>
<th>
pca27
</th>
<th>
pca28
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
142087
</th>
<td>
-0.503552
</td>
<td>
-0.086557
</td>
<td>
0.078180
</td>
<td>
0.126792
</td>
<td>
-0.584275
</td>
<td>
0.205438
</td>
<td>
-0.338339
</td>
<td>
0.301065
</td>
<td>
0.277474
</td>
<td>
-0.326303
</td>
<td>
0.129312
</td>
<td>
0.625587
</td>
<td>
-0.589936
</td>
<td>
1.110826
</td>
<td>
-0.613716
</td>
<td>
0.206283
</td>
<td>
0.647110
</td>
<td>
0.469355
</td>
<td>
-0.617997
</td>
<td>
-0.035442
</td>
<td>
-0.274916
</td>
<td>
0.403849
</td>
<td>
-1.131572
</td>
<td>
0.534247
</td>
<td>
0.506733
</td>
<td>
0.491447
</td>
<td>
-1.164396
</td>
<td>
-0.262446
</td>
<td>
-0.082420
</td>
</tr>
<tr>
<th>
165168
</th>
<td>
-0.445917
</td>
<td>
-0.295530
</td>
<td>
-0.008904
</td>
<td>
0.328010
</td>
<td>
0.591009
</td>
<td>
0.274222
</td>
<td>
1.074437
</td>
<td>
0.179167
</td>
<td>
0.291048
</td>
<td>
0.884476
</td>
<td>
-0.755596
</td>
<td>
-0.313761
</td>
<td>
-0.770876
</td>
<td>
-1.111460
</td>
<td>
-0.231645
</td>
<td>
-0.408441
</td>
<td>
-1.469363
</td>
<td>
0.413926
</td>
<td>
-0.430565
</td>
<td>
-0.612094
</td>
<td>
0.312883
</td>
<td>
-0.148244
</td>
<td>
-0.611249
</td>
<td>
-0.136882
</td>
<td>
-0.126312
</td>
<td>
0.857455
</td>
<td>
-0.303929
</td>
<td>
-0.105879
</td>
<td>
0.042523
</td>
</tr>
<tr>
<th>
235908
</th>
<td>
0.896149
</td>
<td>
-0.289270
</td>
<td>
-0.568506
</td>
<td>
-0.213853
</td>
<td>
0.772360
</td>
<td>
-0.916064
</td>
<td>
-0.826229
</td>
<td>
-1.543692
</td>
<td>
-0.180750
</td>
<td>
1.543498
</td>
<td>
-2.307194
</td>
<td>
0.847058
</td>
<td>
-0.623454
</td>
<td>
-1.268817
</td>
<td>
-0.570688
</td>
<td>
2.311289
</td>
<td>
-1.469729
</td>
<td>
0.404492
</td>
<td>
0.542410
</td>
<td>
1.540824
</td>
<td>
-0.153559
</td>
<td>
0.139862
</td>
<td>
1.148263
</td>
<td>
-1.707982
</td>
<td>
-1.496720
</td>
<td>
-0.135309
</td>
<td>
-0.550657
</td>
<td>
-0.127613
</td>
<td>
0.150344
</td>
</tr>
<tr>
<th>
148255
</th>
<td>
-0.418133
</td>
<td>
-0.359931
</td>
<td>
-0.092716
</td>
<td>
0.091789
</td>
<td>
-0.325522
</td>
<td>
0.539763
</td>
<td>
-0.005340
</td>
<td>
0.631961
</td>
<td>
0.437864
</td>
<td>
0.188399
</td>
<td>
-0.523586
</td>
<td>
-0.853044
</td>
<td>
-0.115711
</td>
<td>
-0.720514
</td>
<td>
-0.651368
</td>
<td>
0.436623
</td>
<td>
-0.990073
</td>
<td>
0.117838
</td>
<td>
-0.525740
</td>
<td>
0.082468
</td>
<td>
0.317526
</td>
<td>
0.196801
</td>
<td>
-0.800332
</td>
<td>
-0.439747
</td>
<td>
-0.188850
</td>
<td>
0.800011
</td>
<td>
-0.290804
</td>
<td>
-0.164921
</td>
<td>
0.053739
</td>
</tr>
<tr>
<th>
145672
</th>
<td>
-0.452670
</td>
<td>
-0.122389
</td>
<td>
0.055489
</td>
<td>
0.482373
</td>
<td>
0.428815
</td>
<td>
0.453595
</td>
<td>
1.774697
</td>
<td>
0.222596
</td>
<td>
-0.215380
</td>
<td>
1.321750
</td>
<td>
-0.540286
</td>
<td>
-0.297360
</td>
<td>
0.915669
</td>
<td>
1.534018
</td>
<td>
-0.618697
</td>
<td>
-1.442722
</td>
<td>
-1.529420
</td>
<td>
0.225133
</td>
<td>
-0.524002
</td>
<td>
-0.002704
</td>
<td>
-0.005569
</td>
<td>
-1.152543
</td>
<td>
-0.617781
</td>
<td>
-0.312699
</td>
<td>
0.493600
</td>
<td>
0.346001
</td>
<td>
-0.893674
</td>
<td>
-0.111020
</td>
<td>
0.052034
</td>
</tr>
</tbody>
</table>
</div>
<h2 id="seems-like-its-working-as-intended">Seems like its working as
intended</h2>
<ul>
<li class="fragment">If we use PCA to generate the same number of
principal components as the number of original features, will we wont be
able to detect anamolies successfuly. When the number of principal
components equals the number of original dimensions, PCA captures nearly
100% of the variance/information in the data as it generates the
principal components, and will have very little error. We will not be
able to differentiate between rare transactions and normal onesâ€”in other
words, anomaly detection will be poor.</li>
<li class="fragment">so lets run PCA for 20 to 30 components and see
what number gives us best performance.</li>
</ul>
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>models<span class="op">=</span> {}</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>scores<span class="op">=</span> {}</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">20</span>,<span class="dv">30</span>):</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    models[<span class="st">&quot;pca&quot;</span><span class="op">+</span><span class="bu">str</span>(j)]<span class="op">=</span> pipe.set_params(<span class="op">**</span>{<span class="st">&quot;model__estimator__n_components&quot;</span>: j })</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>    models[<span class="st">&quot;pca&quot;</span><span class="op">+</span><span class="bu">str</span>(j)].fit(X_train)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    scores[<span class="st">&quot;pca&quot;</span><span class="op">+</span><span class="bu">str</span>(j)]<span class="op">=</span> eval_scores(y_train, models[<span class="st">&quot;pca&quot;</span><span class="op">+</span><span class="bu">str</span>(j)].predict(X_train) )</span></code></pre></div>
<div class="sourceCode" id="cb26"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>pd.concat(scores).sort_values(<span class="st">&quot;recall&quot;</span>, ascending<span class="op">=</span><span class="va">False</span>) </span></code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
</th>
<th>
accuracy
</th>
<th>
recall
</th>
<th>
roc_auc
</th>
<th>
precision
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
pca27
</th>
<th>
0
</th>
<td>
0.999182
</td>
<td>
0.793939
</td>
<td>
0.896739
</td>
<td>
0.748571
</td>
</tr>
<tr>
<th>
pca26
</th>
<th>
0
</th>
<td>
0.998292
</td>
<td>
0.536364
</td>
<td>
0.767728
</td>
<td>
0.505714
</td>
</tr>
<tr>
<th>
pca25
</th>
<th>
0
</th>
<td>
0.998176
</td>
<td>
0.503030
</td>
<td>
0.751032
</td>
<td>
0.474286
</td>
</tr>
<tr>
<th>
pca23
</th>
<th>
0
</th>
<td>
0.997809
</td>
<td>
0.396970
</td>
<td>
0.697910
</td>
<td>
0.374286
</td>
</tr>
<tr>
<th>
pca24
</th>
<th>
0
</th>
<td>
0.997778
</td>
<td>
0.387879
</td>
<td>
0.693357
</td>
<td>
0.365714
</td>
</tr>
<tr>
<th>
pca22
</th>
<th>
0
</th>
<td>
0.997757
</td>
<td>
0.381818
</td>
<td>
0.690321
</td>
<td>
0.360000
</td>
</tr>
<tr>
<th>
pca21
</th>
<th>
0
</th>
<td>
0.997736
</td>
<td>
0.375758
</td>
<td>
0.687286
</td>
<td>
0.354286
</td>
</tr>
<tr>
<th>
pca20
</th>
<th>
0
</th>
<td>
0.997684
</td>
<td>
0.360606
</td>
<td>
0.679697
</td>
<td>
0.340000
</td>
</tr>
<tr>
<th>
pca29
</th>
<th>
0
</th>
<td>
0.997160
</td>
<td>
0.209091
</td>
<td>
0.603808
</td>
<td>
0.197143
</td>
</tr>
<tr>
<th>
pca28
</th>
<th>
0
</th>
<td>
0.996457
</td>
<td>
0.006061
</td>
<td>
0.502117
</td>
<td>
0.005714
</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li class="fragment">we can see from the Score above that 27 PCA
components are the solution for this model and the Recall is .79 and
precision is .75 with roc_auc of almost 0.9.</li>
</ul>
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>pipe.set_params(<span class="op">**</span>{<span class="st">&quot;model__estimator__n_components&quot;</span>: <span class="dv">27</span>})</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>pipe.fit(X_train)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>eval_scores(y_train, pipe.predict(X_train) )</span></code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
accuracy
</th>
<th>
recall
</th>
<th>
roc_auc
</th>
<th>
precision
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
0.999182
</td>
<td>
0.793939
</td>
<td>
0.896739
</td>
<td>
0.748571
</td>
</tr>
</tbody>
</table>
</div>
<div class="sourceCode" id="cb28"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, ConfusionMatrixDisplay</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_train, pipe.predict(X_train), labels<span class="op">=</span> y_train.unique())</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>disp <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix<span class="op">=</span>cm,display_labels<span class="op">=</span> y_train.unique())</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>disp.plot()</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<figure>
<img data-src="mymarkdownfile_files/mymarkdownfile_40_0.png"
alt="png" />
<figcaption aria-hidden="true">png</figcaption>
</figure>
<ul>
<li class="fragment">This results is impressive considering its a
unsupervised model we managed to etect 261 out of 330 fraudulent
transactions.</li>
</ul>
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>preds<span class="op">=</span> pd.concat([y_train, pipe.predict_proba(X_train)], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>preds.columns <span class="op">=</span> [<span class="st">&#39;trueLabel&#39;</span>, <span class="st">&#39;anomalyScore&#39;</span>]</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>preds</span></code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
trueLabel
</th>
<th>
anomalyScore
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
142087
</th>
<td>
0
</td>
<td>
3.343304e-05
</td>
</tr>
<tr>
<th>
165168
</th>
<td>
0
</td>
<td>
5.751799e-06
</td>
</tr>
<tr>
<th>
235908
</th>
<td>
0
</td>
<td>
1.718168e-05
</td>
</tr>
<tr>
<th>
148255
</th>
<td>
0
</td>
<td>
1.329301e-05
</td>
</tr>
<tr>
<th>
145672
</th>
<td>
0
</td>
<td>
6.641812e-06
</td>
</tr>
<tr>
<th>
â€¦
</th>
<td>
â€¦
</td>
<td>
â€¦
</td>
</tr>
<tr>
<th>
30023
</th>
<td>
0
</td>
<td>
1.068002e-07
</td>
</tr>
<tr>
<th>
195475
</th>
<td>
0
</td>
<td>
3.632382e-05
</td>
</tr>
<tr>
<th>
48687
</th>
<td>
0
</td>
<td>
1.021965e-05
</td>
</tr>
<tr>
<th>
159608
</th>
<td>
0
</td>
<td>
2.112043e-05
</td>
</tr>
<tr>
<th>
197673
</th>
<td>
0
</td>
<td>
3.677641e-05
</td>
</tr>
</tbody>
</table>
<p>
190820 rows Ã— 2 columns
</p>
</div>
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>precision, recall, thresholds <span class="op">=</span>  precision_recall_curve(preds[<span class="st">&#39;trueLabel&#39;</span>],preds[<span class="st">&#39;anomalyScore&#39;</span>])</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>average_precision <span class="op">=</span>  average_precision_score(preds[<span class="st">&#39;trueLabel&#39;</span>],preds[<span class="st">&#39;anomalyScore&#39;</span>]).<span class="bu">round</span>(<span class="dv">3</span>)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>px.scatter( x<span class="op">=</span>recall, y<span class="op">=</span> precision, render_mode<span class="op">=</span><span class="st">&#39;webgl&#39;</span>, title<span class="op">=</span>average_precision, width<span class="op">=</span> <span class="dv">1600</span>, height <span class="op">=</span><span class="dv">800</span>).show(<span class="st">&quot;png&quot;</span>)</span></code></pre></div>
<figure>
<img data-src="mymarkdownfile_files/mymarkdownfile_43_0.png"
alt="png" />
<figcaption aria-hidden="true">png</figcaption>
</figure>
<div class="sourceCode" id="cb31"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>fpr,tpr,thresholds <span class="op">=</span> roc_curve(preds[<span class="st">&#39;trueLabel&#39;</span>], preds[<span class="st">&#39;anomalyScore&#39;</span>])</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>areaUnderROC <span class="op">=</span> auc(fpr, tpr)</span></code></pre></div>
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>    px.line(x<span class="op">=</span>fpr, y<span class="op">=</span>tpr, title <span class="op">=</span> <span class="ss">f&#39;area under the curve </span><span class="sc">{</span><span class="bu">round</span>(areaUnderROC,<span class="dv">2</span>)<span class="sc">}</span><span class="ss">&#39;</span>, width<span class="op">=</span><span class="dv">1600</span>, height<span class="op">=</span> <span class="dv">800</span>)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>    .add_scatter(y<span class="op">=</span>[<span class="dv">0</span>,<span class="dv">1</span>], mode<span class="op">=</span><span class="st">&quot;lines&quot;</span>, line_dash<span class="op">=</span> <span class="st">&quot;dash&quot;</span>)    </span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>    .show(<span class="st">&quot;svg&quot;</span>)</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<figure>
<img data-src="mymarkdownfile_files/mymarkdownfile_45_0.svg"
alt="svg" />
<figcaption aria-hidden="true">svg</figcaption>
</figure>
<ul>
<li class="fragment">This results is impressive considering its a
unsupervised model we managed to etect 261 out of 330 fraudulent
transactions.</li>
</ul>
<h2
id="lets-test-our-model-on-test-data-and-look-at-the-precisionrecall-curve-and-roc-auc-curve.">Lets
test our model on test data and look at the precision/recall curve and
roc-auc curve.</h2>
<ul>
<li class="fragment">the below results are impressive again as we are
able to capture almost 80% of Fraud with 70% precision and Area under
the curve is .94.</li>
</ul>
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>preds<span class="op">=</span> pd.concat([y_test, pipe.predict_proba(X_test)], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>preds.columns <span class="op">=</span> [<span class="st">&#39;trueLabel&#39;</span>, <span class="st">&#39;anomalyScore&#39;</span>]</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>preds</span></code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
trueLabel
</th>
<th>
anomalyScore
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
67353
</th>
<td>
0
</td>
<td>
7.976897e-07
</td>
</tr>
<tr>
<th>
67626
</th>
<td>
0
</td>
<td>
6.286458e-06
</td>
</tr>
<tr>
<th>
169699
</th>
<td>
0
</td>
<td>
1.170964e-05
</td>
</tr>
<tr>
<th>
217315
</th>
<td>
0
</td>
<td>
1.436673e-05
</td>
</tr>
<tr>
<th>
111420
</th>
<td>
0
</td>
<td>
3.173962e-05
</td>
</tr>
<tr>
<th>
â€¦
</th>
<td>
â€¦
</td>
<td>
â€¦
</td>
</tr>
<tr>
<th>
70762
</th>
<td>
0
</td>
<td>
5.631365e-06
</td>
</tr>
<tr>
<th>
69843
</th>
<td>
0
</td>
<td>
3.381275e-04
</td>
</tr>
<tr>
<th>
191806
</th>
<td>
0
</td>
<td>
2.466397e-04
</td>
</tr>
<tr>
<th>
259722
</th>
<td>
0
</td>
<td>
1.079170e-06
</td>
</tr>
<tr>
<th>
36616
</th>
<td>
0
</td>
<td>
1.314993e-06
</td>
</tr>
</tbody>
</table>
<p>
93987 rows Ã— 2 columns
</p>
</div>
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>precision, recall, thresholds <span class="op">=</span>  precision_recall_curve(preds[<span class="st">&#39;trueLabel&#39;</span>],preds[<span class="st">&#39;anomalyScore&#39;</span>])</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>average_precision <span class="op">=</span>  average_precision_score(preds[<span class="st">&#39;trueLabel&#39;</span>],preds[<span class="st">&#39;anomalyScore&#39;</span>]).<span class="bu">round</span>(<span class="dv">3</span>)</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>px.scatter( x<span class="op">=</span>recall, y<span class="op">=</span> precision, render_mode<span class="op">=</span><span class="st">&#39;webgl&#39;</span>, title<span class="op">=</span>average_precision, width<span class="op">=</span> <span class="dv">1600</span>, height <span class="op">=</span><span class="dv">800</span>).show(<span class="st">&quot;png&quot;</span>)</span></code></pre></div>
<figure>
<img data-src="mymarkdownfile_files/mymarkdownfile_49_0.png"
alt="png" />
<figcaption aria-hidden="true">png</figcaption>
</figure>
<div class="sourceCode" id="cb35"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>fpr,tpr,thresholds <span class="op">=</span> roc_curve(preds[<span class="st">&#39;trueLabel&#39;</span>], preds[<span class="st">&#39;anomalyScore&#39;</span>])</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>areaUnderROC <span class="op">=</span> auc(fpr, tpr)</span></code></pre></div>
<div class="sourceCode" id="cb36"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>    px.line(x<span class="op">=</span>fpr, y<span class="op">=</span>tpr, title <span class="op">=</span> <span class="ss">f&#39;area under the curve </span><span class="sc">{</span><span class="bu">round</span>(areaUnderROC,<span class="dv">2</span>)<span class="sc">}</span><span class="ss">&#39;</span>, width<span class="op">=</span><span class="dv">1600</span>, height<span class="op">=</span> <span class="dv">800</span>)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>    .add_scatter(y<span class="op">=</span>[<span class="dv">0</span>,<span class="dv">1</span>], mode<span class="op">=</span><span class="st">&quot;lines&quot;</span>, line_dash<span class="op">=</span> <span class="st">&quot;dash&quot;</span>)    </span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>    .show(<span class="st">&quot;svg&quot;</span>)</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<figure>
<img data-src="mymarkdownfile_files/mymarkdownfile_51_0.svg"
alt="svg" />
<figcaption aria-hidden="true">svg</figcaption>
</figure>
<p><a id= '5' ></a> # Conclusion:</p>
<div class="sourceCode" id="cb37"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_classification</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_auc_score ,roc_curve</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a><span class="co"># generate a random dataset</span></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_classification(n_samples<span class="op">=</span><span class="dv">1000</span>, n_classes<span class="op">=</span><span class="dv">2</span>, n_features<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>                            n_informative<span class="op">=</span><span class="dv">3</span>, n_redundant<span class="op">=</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a><span class="co"># split the data into training and testing sets</span></span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a><span class="co"># fit a logistic regression model</span></span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> LogisticRegression(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a>clf.fit(X_train, y_train)</span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "â–¸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "â–¾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style>
<div id="sk-container-id-1" class="sk-top-container">
<div class="sk-text-repr-fallback">
<pre>LogisticRegression(random_state=42)</pre>
<b>In a Jupyter environment, please rerun this cell to show the HTML
representation or trust the notebook. <br />On GitHub, the HTML
representation is unable to render, please try loading this page with
nbviewer.org.</b>
</div>
<div class="sk-container" hidden="">
<div class="sk-item">
<div class="sk-estimator sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">LogisticRegression</label>
<div class="sk-toggleable__content">
<pre>LogisticRegression(random_state=42)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="sourceCode" id="cb38"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># predict probabilities on the test set</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>probs <span class="op">=</span> clf.predict_proba(X_test)[:, <span class="dv">1</span>]</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate the roc_auc score</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>auc <span class="op">=</span> roc_auc_score(y_test, probs)</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the roc curve</span></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>fpr, tpr, thresholds <span class="op">=</span> roc_curve(y_test, probs)</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>plt.plot(fpr, tpr, label<span class="op">=</span><span class="st">&#39;ROC curve (area = </span><span class="sc">%0.2f</span><span class="st">)&#39;</span> <span class="op">%</span> auc)</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], <span class="st">&#39;k--&#39;</span>)</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;False Positive Rate&#39;</span>)</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;True Positive Rate&#39;</span>)</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Receiver operating characteristic example&#39;</span>)</span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&quot;lower right&quot;</span>)</span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a><span class="co"># find the optimal threshold</span></span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>optimal_idx <span class="op">=</span> np.argmax(tpr <span class="op">-</span> fpr)</span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>optimal_threshold <span class="op">=</span> thresholds[optimal_idx]</span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a><span class="co"># create a data frame with the test set predictions and probabilities</span></span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame({<span class="st">&#39;actual&#39;</span>: y_test, <span class="st">&#39;prob&#39;</span>: probs})</span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a><span class="co"># assign a label of 1 or 0 based on the optimal threshold</span></span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;pred&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;prob&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x <span class="op">&gt;=</span> optimal_threshold <span class="cf">else</span> <span class="dv">0</span>)</span>
<span id="cb38-25"><a href="#cb38-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-26"><a href="#cb38-26" aria-hidden="true" tabindex="-1"></a><span class="co"># show the confusion matrix for the optimal threshold</span></span>
<span id="cb38-27"><a href="#cb38-27" aria-hidden="true" tabindex="-1"></a>confusion_matrix <span class="op">=</span> pd.crosstab(df[<span class="st">&#39;actual&#39;</span>], df[<span class="st">&#39;pred&#39;</span>], rownames<span class="op">=</span>[<span class="st">&#39;Actual&#39;</span>], colnames<span class="op">=</span>[<span class="st">&#39;Predicted&#39;</span>])</span>
<span id="cb38-28"><a href="#cb38-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix)</span></code></pre></div>
</section>
    </div>
  </div>

  <script src="https://unpkg.com/reveal.js@^4//dist/reveal.js"></script>

  <!-- reveal.js plugins -->
  <script src="https://unpkg.com/reveal.js@^4//plugin/notes/notes.js"></script>
  <script src="https://unpkg.com/reveal.js@^4//plugin/search/search.js"></script>
  <script src="https://unpkg.com/reveal.js@^4//plugin/zoom/zoom.js"></script>
  <script src="https://unpkg.com/reveal.js@^4//plugin/math/math.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
        // Display controls in the bottom right corner
        controls: true,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: true,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'bottom-right',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: false,

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: false,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: true,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'default',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: true,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'slide',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'fade',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [
          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    </body>
</html>
