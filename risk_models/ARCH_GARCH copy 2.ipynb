{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "pd.set_option('display.max_columns', 150, 'display.max_rows', 100, 'display.max_colwidth', 15)\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "* Time series volatility models, such as GARCH (Generalized Autoregressive Conditional Heteroskedasticity) and ARCH (Autoregressive Conditional Heteroskedasticity) models, work by estimating the conditional variance of a financial time series.\n",
    "\n",
    "* The basic idea behind these models is that volatility tends to cluster together in time, meaning that periods of high volatility are likely to be followed by periods of high volatility, and periods of low volatility are likely to be followed by periods of low volatility. By modeling the conditional variance of the time series, these models attempt to capture these volatility patterns.\n",
    "\n",
    "* The models work by estimating a time-varying variance for the time series, where the variance is a function of past error terms or residuals. The models use the past errors to estimate the current level of volatility and incorporate this estimate into the variance equation. The variance equation may also include lagged values of the conditional variance to capture longer-term volatility patterns.\n",
    "\n",
    "* Once the model is estimated, it can be used to forecast the future volatility of the time series. This can be useful in many applications, such as risk management, portfolio optimization, and option pricing. The models can also be used to test for the presence of volatility clustering and to compare the volatility patterns of different time series.\n",
    "\n",
    "* Overall, time series volatility models work by estimating the conditional variance of a financial time series using past error terms, with the goal of capturing the time-varying patterns of volatility in the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoregressive conditional hetroskadestic model (ARCH Model)\n",
    "Consider the following econometric model:\n",
    "\n",
    "$Y_t = \\rho Y_{t-1} +\\beta X + \\epsilon_t \\qquad\\qquad\\qquad(1)$\n",
    "\n",
    "Here, $Y_t$ is the dependent variable at time $t$, $Y_{t-1}$ is the dependent variable at time $t-1$, $X$ is the independent variable, $\\beta$ is the coefficient of the independent variable,\n",
    "and $\\epsilon_t$ is the disturbance term (error or residuals) . It is usually assumed that the variance of the disturbance term, denoted as $\\sigma^2$, is constant over time.\n",
    "However, it is possible to allow the variance of the disturbance term to change over time. \n",
    "Engle proposed modeling the conditional disturbance variance as an autoregressive conditional heteroscedasticity (ARCH) process of order $p$:\n",
    "\n",
    "$\\sigma_t^2 = \\alpha_0 + \\alpha_1\\epsilon_{t-1}^2 + \\dots + \\alpha_p\\epsilon_{t-p}^2 \\qquad\\qquad\\qquad(2)$\n",
    "\n",
    "The lagged $\\epsilon^2$ terms are called ARCH terms, and the model shown in Equation (2) is known as an ARCH(p) model. \n",
    "\n",
    "The conditional disturbance variance is the variance of $\\epsilon_t$ conditional on information available at time $t-1$, i.e.,\n",
    "\n",
    "Variance = $\\frac{1}{n} \\sum_{i=1}^n (\\epsilon_i - \\mu)^2$ and \n",
    "\n",
    "standard deviation =  $\\sqrt{\\frac{1}{n} \\sum_{i=1}^n (\\epsilon_i - \\mu)^2}$\n",
    "\n",
    "$\\sigma_t^2 = \\mathrm{var}(\\epsilon_t|\\epsilon_{t-1},\\ldots,\\epsilon_{t-p}) $\n",
    "\n",
    "can be read as \"the conditional variance of the error term at time t is equal to the conditional variance of ε_t given the past p error terms, ε_t-1 to ε_t-p\".\n",
    "\n",
    "$ = \\mathrm{E}(\\epsilon_{t}^2|\\epsilon_{t-1}^2,\\ldots,\\epsilon_{t-p}^2) $\n",
    "\n",
    "can be read as \"the conditional variance of the error term at time t is equal to the conditional expectation of ε_t squared, given the past p-1 error terms, ε_t-1^2 to ε_t-p-1^2\". This equation is often used to estimate the parameters of the GARCH model.\n",
    "\n",
    "$ = (\\epsilon{t}^2) \\mathrm{E}{t-1} \\qquad\\qquad\\qquad(3)$\n",
    "\n",
    "can be read as \"the conditional variance of the error term at time t is equal to the conditional expectation of ε_t squared, given all the past error terms up to t-1\". This equation shows that the conditional variance at time t depends only on the past information up to t-1, which makes it a useful property for forecasting.\n",
    "\n",
    "\n",
    "where $\\mathrm{E}_{t-1}$ indicates taking an expectation conditional on all information up to the end of period $t-1$. \n",
    "\n",
    "The model shown in Equation (2) implies that recent disturbances influence the variance of the current disturbance - the ARCH terms can be interpreted as news about volatility (or volatility shocks) from prior periods.\n",
    "\n",
    "A conditional disturbance variance like that shown in Equation (2) can be obtained if the disturbance term is defined as\n",
    "\n",
    "$\\epsilon_t = \\nu_t\\sqrt{\\sigma_t^2} \\qquad\\qquad\\qquad(4)$\n",
    "\n",
    "where $\\nu_t$ is distributed as a standard normal white noise process (mean-zero, variance-one) and $\\sigma_t^2$ is the conditional disturbance variance shown above.\n",
    "\n",
    "The variable $\\nu_t$ is a random error term that represents unpredictable and uncorrelated deviations from a mean or expected value. \n",
    "\n",
    "It's called an error term because it accounts for the difference between the observed value of a variable and its predicted or modeled value.\n",
    "\n",
    "The term $\\sqrt{\\sigma_t^2}$ represents the square root of the variance of a stochastic process at time $t$. In finance, a stochastic process is a mathematical model that describes the evolution of a financial variable over time, where some or all of the variables involved are random or unpredictable.\n",
    "\n",
    "Financial variables that are often modeled using stochastic processes include stock prices, interest rates, exchange rates, and commodity prices. These variables are subject to a wide range of unpredictable factors, such as changes in market sentiment, economic conditions, and geopolitical events.\n",
    "\n",
    "The variance measures the variability or spread of a set of data points around their mean value. In this case, the stochastic process is assumed to be random and unpredictable, so the variance reflects the extent of its fluctuations at time $t$.\n",
    "\n",
    "Multiplying $\\nu_t$ by $\\sqrt{\\sigma_t^2}$ gives us a way to standardize or normalize the random fluctuations of the stochastic process at time $t$. This means that we can compare the magnitude or extent of the fluctuations across different time points or processes in a meaningful way.\n",
    "\n",
    "\n",
    "\n",
    "This model is often simply written as\n",
    "\n",
    "$Y_t = \\rho Y_{t-1} + X\\beta + \\epsilon_t \\qquad\\qquad\\qquad(5)$\n",
    "\n",
    "with the disturbance term $\\epsilon_t$ assumed to be distributed as\n",
    "\n",
    "$\\epsilon_t \\sim \\mathcal{N}(0,\\sigma_t^2) \\qquad\\qquad\\qquad(6)$\n",
    "\n",
    "Where\n",
    "\n",
    "$\\sigma^2_t = \\alpha_0 + \\alpha_1 \\varepsilon^2_{t-1} + \\cdots + \\alpha_p \\varepsilon^2_{t-p} \\qquad\\qquad\\qquad(7)$\n",
    "\n",
    "\n",
    "We can test for ARCH effects fairly simply.\n",
    "\n",
    "* Run a regression of Y on X. Obtain the residuals $\\hat{\\varepsilon}_t$.\n",
    "\n",
    "* Compute the OLS regression: $\\hat{\\varepsilon}^2_t = \\hat{\\alpha}_0 + \\hat{\\alpha}_1 \\hat{\\varepsilon}^2{t-1} + \\cdots + \\hat{\\alpha}p \\hat{\\varepsilon}^2{t-p}$\n",
    "\n",
    "* Test the join significance of $\\hat{\\alpha}_1$, $\\hat{\\alpha}_2$, $\\hat{\\alpha}_3$ etc.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARCH(1) Models\n",
    "\n",
    "The ARCH(1) model is the simplest form of the Autoregressive Conditional Heteroskedasticity (ARCH) model.\n",
    "\n",
    "The model assumes that the conditional disturbance variance, i.e. $\\text{var}(\\varepsilon_t|\\varepsilon_{t-1})$, is a function of the square of the\n",
    "\n",
    "immediate past error term, $\\varepsilon_{t-1}$. Specifically, the conditional disturbance variance is given by:\n",
    "\n",
    "$\\sigma^2_t = \\alpha_0 + \\alpha_1 \\varepsilon^2_{t-1} \\qquad\\qquad\\qquad(30)$\n",
    "\n",
    "where $\\alpha_0$ and $\\alpha_1$ are the parameters of the model. The model equation is therefore:\n",
    "\n",
    "$Y_t = \\rho Y_{t-1} + X\\beta + \\nu_t \\sqrt{\\alpha_0 + \\alpha_1 \\varepsilon^2_{t-1}} \\qquad\\qquad\\qquad(31)$\n",
    "\n",
    "where $Y_t$ is the dependent variable, $\\rho$ is the autoregressive parameter, $X$ is the independent variable, $\\beta$ is the slope coefficient, $\\nu_t$ is the disturbance term, and $\\varepsilon_t$ is the error term.\n",
    "\n",
    "The expected value of the error term, $E[\\varepsilon_t]$, is zero, as shown by:\n",
    "\n",
    "$E[\\varepsilon_t] = E\\left[\\nu_t \\sqrt{\\alpha_0 + \\alpha_1 \\varepsilon^2_{t-1}}\\right] = E[\\nu_t]E\\left[\\sqrt{\\alpha_0 + \\alpha_1 \\varepsilon^2_{t-1}}\\right] = 0 \\qquad\\qquad\\qquad(32)$\n",
    "\n",
    "since $E[\\nu_t] = 0$. Additionally, the expected value of $Y_t$ is equal to $X\\beta$, making this model a classical regression model.\n",
    "\n",
    "While the unconditional disturbance variance, also known as the long-run variance, is constant and given by:\n",
    "\n",
    "$\\text{var}(\\varepsilon_t) = \\frac{\\alpha_0}{1-\\alpha_1} \\qquad\\qquad\\qquad(33)$\n",
    "\n",
    "the conditional disturbance variance, also known as the short-run variance, varies over time and is given by:\n",
    "\n",
    "$\\text{var}(\\varepsilon_t|\\varepsilon_{t-1}) = \\alpha_0 + \\alpha_1 \\varepsilon^2_{t-1} = \\sigma^2_t \\qquad\\qquad\\qquad(34)$\n",
    "\n",
    "    This means that the error term is conditionally heteroskedastic with respect to the immediate past error term. The ARCH(1) model provides us with the following features:\n",
    "\n",
    "* The short-run (conditional) variance (volatility) of the series is a function of the immediate past values of the (square of the) error term.\n",
    "\n",
    "* The effect of each new shock $\\epsilon_t$ depends, in part, on the size of the shock in the previous period. A large shock in period $t$ increases the effect on $Y$ of shocks in periods $t+1$, $t+2$, etc.*\n",
    "\n",
    "* Large shocks tend to cluster together, causing the series to go through periods of large volatility and periods of low volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import scipy.optimize as opt\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "from arch import arch_model\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['savefig.dpi'] = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data for stocks\n",
    "for S&P 500 stocks from 01-01-2010 to 01-08-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = '^GSPC'\n",
    "start = datetime.datetime(2010, 1, 1)\n",
    "end = datetime.datetime(2021, 8, 1)\n",
    "s_p500 = yf.download(stocks, start=start, end = end, interval='1d')\n",
    "s_p500"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rename all columns to lower letters and remove spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_p500.columns =  [x.lower().replace(\" \", \"\") for x in s_p500.columns]\n",
    "s_p500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    s_p500\n",
    "    .reset_index()\n",
    "    .melt(id_vars= \"Date\")\n",
    "    .plot.line(\n",
    "    x= \"Date\" ,y= \"value\",\n",
    "    facet_col= \"variable\",\n",
    "    facet_col_wrap= 3, \n",
    "    color= \"variable\", \n",
    "    height= 800, width= 1400)\n",
    "    .update_yaxes(matches=None) \n",
    "       \n",
    "    ).show(\"png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take percentage change, which is the change in value today compared to yesterday. \n",
    "\n",
    "We can change the number to 2, 3, 4 if we want to take percentage change comapred to more than one day ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_p500.head().pct_change(1)#[1:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate returns based on adjclose price\n",
    "\n",
    "we take percentage change from previous value compared to todays values as returns (ret)\n",
    "\n",
    "difference between yesterday and todays values will be gains or losses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = 100 * (s_p500.pct_change()[1:][['adjclose']])\n",
    "ret"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To gauge the extent to which proposed models account for the real-world situation, we need to calculate the return volatility, which is also known as realized volatility.\n",
    "\n",
    "Realized volatility is the square root of realized variance (standard deviation), which is the sum of squared returns.\n",
    "\n",
    "Realized volatility is used to calculate the performance of the volatility prediction method. Here is the formula for return volatility:\n",
    "\n",
    "$$\\sigma = \\sqrt{\\frac{1}{n-1} \\sum_{n=1}^{N} (r_n - \\mu)^2}$$\n",
    "\n",
    "where $\\sigma$ is the return volatility, $n$ is the number of returns, $N$ is the total number of returns, $r_n$ is the return at time $n$, and $\\mu$ is the mean return.\n",
    "\n",
    "By using this formula, we can measure the volatility of returns over a given period, and use it to compare the performance of different volatility models.\n",
    "\n",
    "We calculate volatility over the period of 5, as rolling std deviation of 5 window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret= ret.assign(realized_vol= ret.rolling(5).std())\n",
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ret\n",
    "    .reset_index()\n",
    "    .melt(id_vars = \"Date\")\n",
    "    .plot(\n",
    "    x= \"Date\", y= \"value\", \n",
    "    facet_row = \"variable\", color=\"variable\" ,\n",
    "    height= 800,\n",
    "    width= 1400\n",
    "    )\n",
    ").show(\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 252\n",
    "split_date = ret.iloc[-n:].index\n",
    "split_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = arch_model(ret.adjclose.iloc[-n:], mean='zero', vol='ARCH', p=1).fit(disp='off')\n",
    "print(arch.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Iterating ARCH parameter p over specified interval\n",
    "\n",
    "* Running ARCH model with different p values\n",
    "\n",
    "* Finding the minimum BIC score to select the best model\n",
    "\n",
    "* Running ARCH model with the best p value\n",
    "\n",
    "* Forecasting the volatility based on the optimized ARCH model\n",
    "\n",
    "* Calculating the root mean square error (RMSE) score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_arch = []\n",
    "for p in range(1, 5):\n",
    "        arch = arch_model(ret.adjclose.iloc[-n:], mean='zero', vol='ARCH', p=p).fit(disp='off')\n",
    "        bic_arch.append(arch.bic)\n",
    "        if arch.bic == np.min(bic_arch):\n",
    "            best_param = p\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = arch_model(ret.adjclose.iloc[-n:], mean='zero', vol='ARCH', p=best_param).fit(disp='off')\n",
    "print(arch.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_arch = arch.forecast(start=split_date[0])\n",
    "forecast_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_arch = np.sqrt(mse(\n",
    "    ret.realized_vol[-n:]/ 100, \n",
    "    np.sqrt(\n",
    "    forecast_arch.variance.iloc[-len(split_date):] / 100\n",
    "    )))\n",
    "print('The RMSE value of ARCH model is {:.4f}'.format(rmse_arch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frcts_values= forecast_arch.variance.iloc[-len(split_date):] / 100\n",
    "frcts_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret.realized_vol.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    px.line(x=ret.realized_vol.index, \n",
    "            y=ret.realized_vol / 100, title='Realized Volatility',\n",
    "            color_discrete_sequence=['blue'],\n",
    "            width=1000\n",
    "            )\n",
    "    .add_trace(px.line(x=frcts_values.index , \n",
    "                       y = frcts_values[\"h.1\"],\n",
    "                       color_discrete_sequence=['red'],                       \n",
    "                ).data[0] )  \n",
    "    \n",
    " )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalised conditional hetroskadestic model (GARCH models)\n",
    "\n",
    "it is possible to model higher order ARCH models. However, these models are difficult to estimate for higher orders of lag since they often produce negative estimates of the $\\alpha s$.\n",
    "\n",
    "To solve this problem, people have turned to the GARCH model (Bollerslev 1986).\n",
    "\n",
    "Essentially, the GARCH model turns the AR process of the ARCH model into an ARMA process by adding in a moving average process. In the GARCH model, the conditional disturbance variance is now\n",
    "\n",
    "$\\sigma^2_t = \\alpha_0 + \\alpha_1\\epsilon^2_{t-1} + \\cdots + \\alpha_p\\epsilon^ 2_{t-p} + \\gamma_1\\sigma^2_{t-1} + \\gamma_2\\sigma^2_{t-2} + \\cdots + \\gamma_q\\sigma^2_{t-q}$\n",
    "\n",
    "$\\sigma^2_t = \\alpha_0 + \\sum_{j=1}^{p} \\alpha_j \\epsilon^2_{t-j} + \\sum_{k=1}^{q} \\gamma_k \\sigma^2_{t-k} \\qquad\\qquad\\qquad(1)$\n",
    "\n",
    "Thus, the current variance can be seen to depend on all previous squared disturbances; however, the effect of these disturbances declines exponentially over time. As in the ARCH model, we need to impose some parameter restrictions to ensure that the series is variance-stationary: in the GARCH(1,1) case, we require\n",
    "\n",
    "$\\alpha > 0$, $\\gamma_1 \\geq 0$, $\\alpha_0 \\geq 0$,  and $\\alpha_1 + \\gamma_1 < 1$.\n",
    "\n",
    "\n",
    "It is now easy to see that the value of the conditional disturbance variance depends on both the past values of the shocks and on the past values of itself. The simplest GARCH model is the GARCH(1,1) model i.e.\n",
    "\n",
    "$\\sigma^2_t = \\alpha_0 + \\alpha_1\\ \\epsilon^2_{t-1} + \\gamma_1\\sigma^2_{t-1}$\n",
    "\n",
    "The ARCH model is unable to capture the influence of historical innovations. However, as a more parsimonious model, the GARCH model can account for the change in historical innovations because GARCH models can be expressed as an infiniteorder ARCH. Let’s see how GARCH can be shown as an infinite order of ARCH:\n",
    "\n",
    "$= \\alpha_0 + \\alpha_1\\epsilon^ 2_{t-1} + \\gamma_1(\\alpha_0 + \\alpha_1\\epsilon^ 2_{t-2} + \\gamma_1\\sigma^2_{t-2})$\n",
    "\n",
    "$= \\alpha_0 + \\alpha_1\\epsilon^2_{t-1} + \\gamma_1\\alpha_0 + \\gamma_1\\alpha_1\\epsilon^ 2_{t-2} + \\gamma_1^2\\sigma^2_{t-2} $\n",
    "\n",
    "$\\vdots$\n",
    "\n",
    "$\\sigma^2_t =\\frac{\\alpha_0}{( 1 - \\gamma_1)}  +\\alpha_1(\\epsilon^ 2_{t-1}+ \\gamma_1\\epsilon^ 2_{t-2} +\\gamma_1^2 \\epsilon^ 2_{t-3} + \\cdots)$\n",
    "\n",
    "The nice thing about both the ARCH and GARCH setups is that they allow the conditional variance to be influenced by exogenous variables i.e. independent variables that we might be interested in. For example, we might be interested in how political events affect exchange rate volatility (Leblang & Bernhard 2006). If these exogenous variables are $I_t$, then the conditional variance in a GARCH(1,1) model is\n",
    "\n",
    "$\\sigma^2_t = \\alpha_0 + \\alpha_1 \\epsilon^2_{t-1} + \\gamma_1 \\sigma^2_{t-1} + \\delta I_t$\n",
    "\n",
    "This allows us to look at how independent variables affect the volatility of time series data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "garch = arch_model(ret.adjclose.iloc[-n:], mean='zero', vol='GARCH', p=1, o=0, q=1).fit(disp='off')\n",
    "print(garch.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_garch = []\n",
    "\n",
    "for p in range(1, 5):\n",
    "    for q in range(1, 5):\n",
    "        garch = arch_model(ret.adjclose.iloc[-n:], mean='zero',vol='GARCH', p=p, o=0, q=q)\\\n",
    "                .fit(disp='off')\n",
    "        bic_garch.append(garch.bic)\n",
    "        if garch.bic == np.min(bic_garch):\n",
    "            best_param = p, q\n",
    "            print(best_param)            \n",
    "garch = arch_model(ret.adjclose.iloc[-n:], mean='zero', vol='GARCH',\n",
    "                   p=best_param[0], o=0, q=best_param[1])\\\n",
    "        .fit(disp='off')\n",
    "print(garch.summary())\n",
    "forecast = garch.forecast(start=split_date[0])\n",
    "forecast_garch = forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frcts_values= forecast_garch.variance.iloc[-len(split_date):] / 100\n",
    "frcts_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_garch = np.sqrt(mse(ret.realized_vol[-n:] / 100,\n",
    "                         np.sqrt(frcts_values[\"h.1\"])\n",
    "                         ))\n",
    "print('The RMSE value of GARCH model is {:.4f}'.format(rmse_garch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frcts_values= forecast_garch.variance.iloc[-len(split_date):] / 100\n",
    "frcts_values\n",
    "(\n",
    "    px.line(x=ret.realized_vol.index, \n",
    "            y=ret.realized_vol / 100, title='Realized Volatility',\n",
    "            color_discrete_sequence=['blue'],\n",
    "            width=1000\n",
    "            )    \n",
    "    .add_scatter(x=frcts_values.index , \n",
    "                       y = frcts_values[\"h.1\"], \n",
    "                       mode=\"lines\",\n",
    "                       line=dict(width= 2, color=\"red\"),\n",
    "                       #marker =dict(size=50, color=\"red\")\n",
    "                       name= \"forecast\"\n",
    "                       )\n",
    "    \n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GJR-GARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_gjr_garch = []\n",
    "\n",
    "for p in range(1, 5):\n",
    "    for q in range(1, 5):\n",
    "        gjrgarch = arch_model(ret.adjclose.iloc[-n:], mean='zero', p=p, o=1, q=q)\\\n",
    "                   .fit(disp='off')\n",
    "        bic_gjr_garch.append(gjrgarch.bic)\n",
    "        if gjrgarch.bic == np.min(bic_gjr_garch):\n",
    "            best_param = p, q\n",
    "gjrgarch = arch_model(ret.adjclose.iloc[-n:],mean='zero', p=best_param[0], o=1,\n",
    "                      q=best_param[1]).fit(disp='off')\n",
    "print(gjrgarch.summary())\n",
    "forecast = gjrgarch.forecast(start=split_date[0])\n",
    "forecast_gjrgarch = forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_gjr_garch = np.sqrt(mse(ret.realized_vol[-n:] / 100,\n",
    "                             np.sqrt(forecast_gjrgarch\\\n",
    "                             .variance.iloc[-len(split_date):]\n",
    "                             / 100)))\n",
    "print('The RMSE value of GJR-GARCH models is {:.4f}'\n",
    "      .format(rmse_gjr_garch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frcts_values= forecast_gjrgarch.variance.iloc[-len(split_date):] / 100\n",
    "frcts_values\n",
    "(\n",
    "    px.line(x= ret.realized_vol.index, \n",
    "            y= ret.realized_vol/ 100, title='Realized Volatility',\n",
    "            color_discrete_sequence=['blue'],\n",
    "            width=1000\n",
    "            )    \n",
    "    .add_scatter(x=frcts_values.index , \n",
    "                       y = frcts_values[\"h.1\"], \n",
    "                       mode=\"lines\",\n",
    "                       line=dict(width= 2, color=\"red\"),\n",
    "                       #marker =dict(size=50, color=\"red\"),\n",
    "                       name= \"forecast\"\n",
    "                       )\n",
    "    \n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EGARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_egarch = []\n",
    "\n",
    "for p in range(1, 5):\n",
    "    for q in range(1, 5):\n",
    "        egarch = arch_model(ret.adjclose.iloc[-n:], mean='zero', vol='EGARCH', p=p, q=q)\\\n",
    "                 .fit(disp='off')\n",
    "        bic_egarch.append(egarch.bic)\n",
    "        if egarch.bic == np.min(bic_egarch):\n",
    "            best_param = p, q\n",
    "egarch = arch_model(ret.adjclose.iloc[-n:], mean='zero', vol='EGARCH',\n",
    "                    p=best_param[0], q=best_param[1])\\\n",
    "         .fit(disp='off')\n",
    "print(egarch.summary())\n",
    "forecast = egarch.forecast(start=split_date[0])\n",
    "forecast_egarch = forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_egarch = np.sqrt(mse(ret.realized_vol[-n:] / 100,\n",
    "                          np.sqrt(forecast_egarch.variance\\\n",
    "                          .iloc[-len(split_date):] / 100)))\n",
    "print('The RMSE value of EGARCH models is {:.4f}'.format(rmse_egarch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frcts_values= forecast_egarch.variance.iloc[-len(split_date):] / 100\n",
    "frcts_values\n",
    "(\n",
    "    px.line(x=ret.realized_vol.index, \n",
    "            y=ret.realized_vol / 100, title='Realized Volatility',\n",
    "            color_discrete_sequence=['blue'],\n",
    "            width=1000\n",
    "            )    \n",
    "    .add_scatter(x=frcts_values.index , \n",
    "                       y = frcts_values[\"h.1\"], \n",
    "                       mode=\"lines\",\n",
    "                       line=dict(width= 2, color=\"red\"),\n",
    "                       #marker =dict(size=50, color=\"red\"),\n",
    "                       name= \"forecast\"\n",
    "                       )\n",
    "    \n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR-GARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from scipy.stats import uniform as sp_rand\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_svm = ret[[\"adjclose\"]] ** 2\n",
    "returns_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_svm = returns_svm.reset_index()\n",
    "returns_svm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del returns_svm['Date']\n",
    "returns_svm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ret\n",
    "X[\"adjclose\"]=  X.adjclose **2 \n",
    "X= X.assign(target = X.iloc[:,1])#.drop(columns= \"realized_vol\") #.shift(-1).iloc[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (\n",
    "    ret\n",
    "    .assign(\n",
    "    adjclose= ret.adjclose **2,\n",
    "    target = ret.iloc[:,1]#.shift(-1)\n",
    "    )\n",
    "    \n",
    "    )\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[4:].copy()#.reset_index(drop=True)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_poly = SVR(kernel='poly', degree=2)\n",
    "svr_lin = SVR(kernel='linear')\n",
    "svr_rbf = SVR(kernel='rbf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR-GARCH-Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_grid = {'gamma': sp_rand(),\n",
    "             'C': sp_rand(),\n",
    "             'epsilon': sp_rand()}\n",
    "clf = RandomizedSearchCV(svr_lin, para_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(10).iloc[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X.iloc[:-n].drop(columns=\"target\"), \n",
    "        X.iloc[:-n][\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_test= (\n",
    "    ((forecast_egarch.variance.iloc[-len(split_date):] ) )\n",
    "    .rename(columns= {\"h.1\": \"adjclose\"})\n",
    "    .assign(\n",
    "    realized_vol= lambda df_ : df_.adjclose.rolling(5).std(),\n",
    "    adjclose= lambda df_ : df_.adjclose ** 2\n",
    "            )    \n",
    "    #.shift(1)\n",
    "    #.dropna()\n",
    "    )\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm= 5-1\n",
    "predict_svr_lin = clf.predict(X_test.iloc[nm:,])\n",
    "predict_svr_lin = pd.DataFrame(predict_svr_lin)\n",
    "predict_svr_lin.index = ret.iloc[-(n-nm) :].index\n",
    "rmse_svr = np.sqrt(mse(ret.realized_vol.iloc[-(n-nm):] / 100,\n",
    "                       predict_svr_lin / 100))\n",
    "print('The RMSE value of SVR with Linear Kernel is {:.6f}'\n",
    "      .format(rmse_svr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(ret.realized_vol / 100, label='Realized Volatility')\n",
    "plt.plot(predict_svr_lin / 100, label='Volatility Prediction-SVR-GARCH')\n",
    "plt.title('Volatility Prediction with SVR-GARCH (Linear)', fontsize=12)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR-GARCH RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_grid ={'gamma': sp_rand(),\n",
    "            'C': sp_rand(),\n",
    "            'epsilon': sp_rand()}\n",
    "clf = RandomizedSearchCV(svr_rbf, para_grid)\n",
    "clf.fit(X.iloc[:-n].values, \n",
    "        realized_vol.iloc[1:-(n-1)].values.reshape(-1,))\n",
    "predict_svr_rbf = clf.predict(X.iloc[-n:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_svr_rbf = pd.DataFrame(predict_svr_rbf)\n",
    "predict_svr_rbf.index = ret.iloc[-n:].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_svr_rbf = np.sqrt(mse(realized_vol.iloc[-n:] / 100,\n",
    "                           predict_svr_rbf / 100))\n",
    "print('The RMSE value of SVR with RBF Kernel is  {:.6f}'\n",
    "      .format(rmse_svr_rbf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(realized_vol / 100, label='Realized Volatility')\n",
    "plt.plot(predict_svr_rbf / 100, label='Volatility Prediction-SVR_GARCH')\n",
    "plt.title('Volatility Prediction with SVR-GARCH (RBF)', fontsize=12)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR-GARCH Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_grid = {'gamma': sp_rand(),\n",
    "            'C': sp_rand(),\n",
    "            'epsilon': sp_rand()}\n",
    "clf = RandomizedSearchCV(svr_poly, para_grid, n_jobs=-1)\n",
    "\n",
    "clf.fit(X.iloc[:-n].values, realized_vol.iloc[1:-(n-1)].values.reshape(-1,))\n",
    "\n",
    "predict_svr_poly = clf.predict(X.iloc[-n:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_svr_poly = pd.DataFrame(predict_svr_poly)\n",
    "predict_svr_poly.index = ret.iloc[-n:].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_svr_poly = np.sqrt(mse(realized_vol.iloc[-n:] / 100,\n",
    "                            predict_svr_poly / 100))\n",
    "print('The RMSE value of SVR with Polynomial Kernel is {:.6f}'\\\n",
    "      .format(rmse_svr_poly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(realized_vol/100, label='Realized Volatility')\n",
    "plt.plot(predict_svr_poly/100, label='Volatility Prediction-SVR-GARCH')\n",
    "plt.title('Volatility Prediction with SVR-GARCH (Polynomial)',\n",
    "          fontsize=12)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN-GARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "NN_vol = MLPRegressor(learning_rate_init=0.001, random_state=1) \n",
    "para_grid_NN = {'hidden_layer_sizes': [(100, 50), (50, 50), (10, 100)],\n",
    "               'max_iter': [500, 1000],\n",
    "               'alpha': [0.00005, 0.0005 ]} \n",
    "clf = RandomizedSearchCV(NN_vol, para_grid_NN)\n",
    "clf.fit(X.iloc[:-n].values, \n",
    "        realized_vol.iloc[1:-(n-1)].values.reshape(-1, ))\n",
    "NN_predictions = clf.predict(X.iloc[-n:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_predictions = pd.DataFrame(NN_predictions)\n",
    "NN_predictions.index = ret.iloc[-n:].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_NN = np.sqrt(mse(realized_vol.iloc[-n:] / 100,\n",
    "                      NN_predictions / 100))\n",
    "print('The RMSE value of NN is {:.6f}'.format(rmse_NN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(realized_vol / 100, label='Realized Volatility')\n",
    "plt.plot(NN_predictions / 100, label='Volatility Prediction-NN')\n",
    "plt.title('Volatility Prediction with Neural Network', fontsize=12)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL-GARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [layers.Dense(256, activation=\"relu\"),\n",
    "     layers.Dense(128, activation=\"relu\"),\n",
    "     layers.Dense(1, activation=\"linear\"),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_trial = np.arange(100, 400, 4)\n",
    "batch_trial = np.arange(100, 400, 4)\n",
    "DL_pred = []\n",
    "DL_RMSE = []\n",
    "for i, j, k in zip(range(4), epochs_trial, batch_trial):\n",
    "    model.fit(X.iloc[:-n].values,\n",
    "              realized_vol.iloc[1:-(n-1)].values.reshape(-1,),\n",
    "              batch_size=k, epochs=j, verbose=False)\n",
    "    DL_predict = model.predict(np.asarray(X.iloc[-n:]))\n",
    "    DL_RMSE.append(np.sqrt(mse(realized_vol.iloc[-n:] / 100,\n",
    "                            DL_predict.flatten() / 100)))\n",
    "    DL_pred.append(DL_predict)\n",
    "    print('DL_RMSE_{}:{:.6f}'.format(i+1, DL_RMSE[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DL_predict = pd.DataFrame(DL_pred[DL_RMSE.index(min(DL_RMSE))])\n",
    "DL_predict.index = ret.iloc[-n:].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(realized_vol / 100,label='Realized Volatility')\n",
    "plt.plot(DL_predict / 100,label='Volatility Prediction-DL')\n",
    "plt.title('Volatility Prediction with Deep Learning',  fontsize=12)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7cb1b9ae4d417fedf7f40a8eec98f7cfbd359e096bd857395a915f4609834ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
